{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d0be24d-2f8b-4c7c-a011-3c68a3ff26fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea4bcd47-8d7a-42f5-b6f8-a3e53e9585b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+------+\n| id|    name|age|salary|address|gender|\n+---+--------+---+------+-------+------+\n|  1|  Manish| 26| 75000|  INDIA|     m|\n|  2|  Nikita| 23|100000|    USA|     f|\n|  3|  Pritam| 22|150000|  INDIA|     m|\n|  4|Prantosh| 17|200000|  JAPAN|     m|\n|  5|  Vikash| 31|300000|    USA|     m|\n|  6|   Rahul| 55|300000|  INDIA|     m|\n|  7|    Raju| 67|540000|    USA|     m|\n|  8| Praveen| 28| 70000|  JAPAN|     m|\n|  9|     Dev| 32|150000|  JAPAN|     m|\n| 10|  Sherin| 16| 25000| RUSSIA|     f|\n| 11|    Ragu| 12| 35000|  INDIA|     f|\n| 12|   Sweta| 43|200000|  INDIA|     f|\n| 13| Raushan| 48|650000|    USA|     m|\n| 14|  Mukesh| 36| 95000| RUSSIA|     m|\n| 15| Prakash| 52|750000|  INDIA|     m|\n+---+--------+---+------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"inferSchema\", \"false\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"mode\", \"PERMISSIVE\")\\\n",
    "    .load(\"/FileStore/tables/employee_write-1.csv\")\n",
    "\n",
    "df.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12965c36-6697-45fd-9e82-c0fb37b8ad8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "        .option(\"mode\", \"overwrite\")\\\n",
    "            .option(\"path\", \"/FileStore/tables/partition_by_address.csv\")\\\n",
    "                .partitionBy(\"address\")\\\n",
    "                .save()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1d7bb85-d3d1-496e-8120-a990e1f96e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: DataFrame[id: string, name: string, age: string, salary: string, address: string, gender: string]"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "993c17e0-0570-4a9f-9953-7c55d511c1b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: [FileInfo(path='dbfs:/FileStore/tables/partition_by_address.csv/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1745815977000),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address.csv/address=INDIA/', name='address=INDIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address.csv/address=JAPAN/', name='address=JAPAN/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address.csv/address=RUSSIA/', name='address=RUSSIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address.csv/address=USA/', name='address=USA/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables/partition_by_address.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "065b9c06-87f4-41ce-90b9-51238dc0d344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "        .option(\"mode\", \"overwrite\")\\\n",
    "            .option(\"path\", \"/FileStore/tables/partition_by_address_gender.csv\")\\\n",
    "                .partitionBy(\"address\", \"gender\")\\\n",
    "                .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9939e2c-97b4-4ba9-9551-61cded2cd81b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: [FileInfo(path='dbfs:/FileStore/tables/partition_by_address_gender.csv/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1745816430000),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address_gender.csv/address=INDIA/', name='address=INDIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address_gender.csv/address=JAPAN/', name='address=JAPAN/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address_gender.csv/address=RUSSIA/', name='address=RUSSIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_address_gender.csv/address=USA/', name='address=USA/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables/partition_by_address_gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0cc5616-9888-466a-9b5f-abe015dd4667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[13]: [FileInfo(path='dbfs:/FileStore/tables/partition_by_address_gender.csv/address=JAPAN/gender=m/', name='gender=m/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/tables/partition_by_address_gender.csv/address=JAPAN/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763d390a-0430-4abc-b0d9-3fc589b8f0a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "        .option(\"mode\", \"overwrite\")\\\n",
    "            .option(\"path\", \"/FileStore/tables/partition_by_gender_address.csv\")\\\n",
    "                .partitionBy(\"gender\",\"address\")\\\n",
    "                    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14edbfe4-0bd7-48f4-9a97-3e911b889b49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[15]: [FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1745816685000),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/', name='gender=f/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=m/', name='gender=m/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables/partition_by_gender_address.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2f320e-6e87-4a66-a920-5dcca36ca55f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[16]: [FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=INDIA/', name='address=INDIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/', name='address=RUSSIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=USA/', name='address=USA/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfee4926-9f94-4e6a-84cd-6ef49225d597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[17]: [FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1745816685000),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/_committed_6292005306882208804', name='_committed_6292005306882208804', size=111, modificationTime=1745816685000),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/_started_6292005306882208804', name='_started_6292005306882208804', size=0, modificationTime=1745816683000),\n FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/part-00000-tid-6292005306882208804-66796614-0f6a-4390-86b9-b05464c5ee24-6-2.c000.csv', name='part-00000-tid-6292005306882208804-66796614-0f6a-4390-86b9-b05464c5ee24-6-2.c000.csv', size=38, modificationTime=1745816683000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd777ec1-3dc6-4267-8618-3a718e146c1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[18]: [FileInfo(path='dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/_committed_6292005306882208804', name='_committed_6292005306882208804', size=111, modificationTime=1745816685000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/tables/partition_by_gender_address.csv/gender=f/address=RUSSIA/_committed_6292005306882208804\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cfca2b0-4989-4535-b0ed-cd942305ee53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "my_data =   [(1,1),    \n",
    "  (2,1),    \n",
    "  (3,1),    \n",
    "  (4,2),    \n",
    "  (5,1),    \n",
    "  (6,2),    \n",
    "  (7,2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5635497-ca83-4f83-bc18-4b9695f8444b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "my_schema = ['id' ,'num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59184385-b1b9-487f-8b6d-b26d79411ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n| id|num|\n+---+---+\n|  1|  1|\n|  2|  1|\n|  3|  1|\n|  4|  2|\n|  5|  1|\n|  6|  2|\n|  7|  2|\n+---+---+\n\n"
     ]
    }
   ],
   "source": [
    "mf_df = spark.createDataFrame(data=my_data, schema=my_schema)\n",
    "\n",
    "mf_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51865d36-f594-4967-a584-ac08ed2574c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n| id|    name|age|salary|     address| nominee|\n+---+--------+---+------+------------+--------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|  3|  Pritam| 22|150000|   Bangalore|   India|\n|  4|Prantosh| 17|200000|     Kolkata|   India|\n|  5|  Vikash| 31|300000|        null|nominee5|\n+---+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "        .option(\"mode\", \"PERMISSIVE\")\\\n",
    "            .load(\"/FileStore/tables/employee.csv\")\n",
    "\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28afe26d-4b8f-4a4d-91cc-512db72e0d39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- salary: string (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ef6865-b0cd-4706-b5bf-65310e00f88e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[36]: ['id', 'name', 'age', 'salary', 'address', 'nominee']"
     ]
    }
   ],
   "source": [
    "employee_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18738607-ae21-471f-aead-9a9a27042514",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|    name|\n+--------+\n|  Manish|\n|  Nikita|\n|  Pritam|\n|Prantosh|\n|  Vikash|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e34abe6-95a4-4626-882d-7853ec81448a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|    name|\n+--------+\n|  Manish|\n|  Nikita|\n|  Pritam|\n|Prantosh|\n|  Vikash|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(col(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e114b5c-2d58-47c4-8e45-d6312edacd26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|(id + 5)|\n+--------+\n|     6.0|\n|     7.0|\n|     8.0|\n|     9.0|\n|    10.0|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(col(\"id\")+ 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06b29a95-b4ce-4175-8e9d-3aa7c8db1d7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+\n|    name|age|salary|\n+--------+---+------+\n|  Manish| 26| 75000|\n|  Nikita| 23|100000|\n|  Pritam| 22|150000|\n|Prantosh| 17|200000|\n|  Vikash| 31|300000|\n+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"name\", \"age\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f0675e-a690-41bd-96f7-b65da61c6313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+------------+\n|    name|age|salary|     address|\n+--------+---+------+------------+\n|  Manish| 26| 75000|       bihar|\n|  Nikita| 23|100000|uttarpradesh|\n|  Pritam| 22|150000|   Bangalore|\n|Prantosh| 17|200000|     Kolkata|\n|  Vikash| 31|300000|        null|\n+--------+---+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"name\", col(\"age\"), employee_df[\"salary\"], employee_df.address).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c20fe046-caa0-4ad5-aaf1-6cb748982d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4341238895431293>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43memployee_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid + 5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n",
       "\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n",
       "\u001B[1;32m   2979\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   2980\u001B[0m \n",
       "\u001B[1;32m   2981\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3021\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n",
       "\u001B[1;32m   3022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   3024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id + 5` cannot be resolved. Did you mean one of the following? [`id`, `address`, `age`, `name`, `nominee`].;\n",
       "'Project ['id + 5]\n",
       "+- Relation [id#953,name#954,age#955,salary#956,address#957,nominee#958] csv\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-4341238895431293>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43memployee_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid + 5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   2979\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   2980\u001B[0m \n\u001B[1;32m   2981\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3021\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n\u001B[1;32m   3022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id + 5` cannot be resolved. Did you mean one of the following? [`id`, `address`, `age`, `name`, `nominee`].;\n'Project ['id + 5]\n+- Relation [id#953,name#954,age#955,salary#956,address#957,nominee#958] csv\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id + 5` cannot be resolved. Did you mean one of the following? [`id`, `address`, `age`, `name`, `nominee`].;\n'Project ['id + 5]\n+- Relation [id#953,name#954,age#955,salary#956,address#957,nominee#958] csv\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "employee_df.select(\"id + 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d89a290e-9d1a-458d-b72f-64f3ba4e9ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4188b9b9-e270-4b7b-9b92-bec269fd2665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|(id + 5)|\n+--------+\n|     6.0|\n|     7.0|\n|     8.0|\n|     9.0|\n|    10.0|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(expr(\"id + 5\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ae25b7c-380f-4f60-a3c2-18b4b6d09998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------------------+\n|Employee_name|Id_Salary|concat(name, address)|\n+-------------+---------+---------------------+\n|       Manish|   175000|          Manishbihar|\n|       Nikita|  2100000|   Nikitauttarpradesh|\n|       Pritam|  3150000|      PritamBangalore|\n|     Prantosh|  4200000|      PrantoshKolkata|\n|       Vikash|  5300000|                 null|\n+-------------+---------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(expr(\"name as Employee_name\"),expr(\"concat(id, salary) as Id_Salary\") ,expr(\"concat(name, address)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec007b10-9a62-4076-a583-315152ec3d1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n| id|    name|age|salary|     address| nominee|\n+---+--------+---+------+------------+--------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|  3|  Pritam| 22|150000|   Bangalore|   India|\n|  4|Prantosh| 17|200000|     Kolkata|   India|\n|  5|  Vikash| 31|300000|        null|nominee5|\n+---+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a6c24cf-d73d-4b60-8ec3-38cb8d1fb88f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SPARK SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ccabc9-9ed5-47b7-8770-34648b4931e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "employee_df.createOrReplaceTempView(\"employee_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c0251d8-348f-4d67-b150-6a90c2fe3255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n| id|    name|age|salary|     address| nominee|\n+---+--------+---+------+------------+--------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|  3|  Pritam| 22|150000|   Bangalore|   India|\n|  4|Prantosh| 17|200000|     Kolkata|   India|\n|  5|  Vikash| 31|300000|        null|nominee5|\n+---+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from employee_tbl\n",
    "          \"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9dc7a92-751d-4ab7-8556-fee9073330e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+\n|employee_id|    name|age|salary|\n+-----------+--------+---+------+\n|          1|  Manish| 26| 75000|\n|          2|  Nikita| 23|100000|\n|          3|  Pritam| 22|150000|\n|          4|Prantosh| 17|200000|\n|          5|  Vikash| 31|300000|\n+-----------+--------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(col(\"id\").alias(\"employee_id\"), \"name\", \"age\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7bae709-7a9f-46da-9770-61bffeda5c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Filter and Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "889ee8ea-ffae-41a7-a4d4-54af00a919e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------+-------+--------+\n| id|  name|age|salary|address| nominee|\n+---+------+---+------+-------+--------+\n|  5|Vikash| 31|300000|   null|nominee5|\n+---+------+---+------+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.filter(col(\"salary\")> 200000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13954f47-89d0-4c93-b3cc-4637fa257154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------+-------+--------+\n| id|  name|age|salary|address| nominee|\n+---+------+---+------+-------+--------+\n|  5|Vikash| 31|300000|   null|nominee5|\n+---+------+---+------+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.where(col(\"salary\")> 200000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6102858b-1f41-4b26-865d-9ad5633c9872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------+-------+--------+\n| id|  name|age|salary|address| nominee|\n+---+------+---+------+-------+--------+\n|  5|Vikash| 31|300000|   null|nominee5|\n+---+------+---+------+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.filter((col(\"salary\")> 150000) & (col(\"age\")> 18)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df2d939c-abf1-43c7-bd00-2dccded59e68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Literal (lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d2023a2-d3e4-4b6a-b7d0-a728a82a58d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+---------+\n| id|    name|age|salary|     address| nominee|last_name|\n+---+--------+---+------+------------+--------+---------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|    kumar|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|    kumar|\n|  3|  Pritam| 22|150000|   Bangalore|   India|    kumar|\n|  4|Prantosh| 17|200000|     Kolkata|   India|    kumar|\n|  5|  Vikash| 31|300000|        null|nominee5|    kumar|\n+---+--------+---+------+------------+--------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"*\",lit(\"kumar\").alias(\"last_name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19722e36-f2e3-4a4e-ba99-126b61b4547a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "WithColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7efdc65b-b0ed-4e1a-9305-496f4b4021e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+-------+\n| id|    name|age|salary|     address| nominee|surname|\n+---+--------+---+------+------------+--------+-------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|  singh|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|  singh|\n|  3|  Pritam| 22|150000|   Bangalore|   India|  singh|\n|  4|Prantosh| 17|200000|     Kolkata|   India|  singh|\n|  5|  Vikash| 31|300000|        null|nominee5|  singh|\n+---+--------+---+------+------------+--------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.withColumn(\"surname\", lit(\"singh\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9273f387-348d-4cfe-956b-927e7e3542ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+------------+--------+\n|employee_id|    name|age|salary|     address| nominee|\n+-----------+--------+---+------+------------+--------+\n|          1|  Manish| 26| 75000|       bihar|nominee1|\n|          2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|          3|  Pritam| 22|150000|   Bangalore|   India|\n|          4|Prantosh| 17|200000|     Kolkata|   India|\n|          5|  Vikash| 31|300000|        null|nominee5|\n+-----------+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.withColumnRenamed(\"id\", \"employee_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ed1ade-6d1e-4336-8d37-9e471a108a48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_employee_df = employee_df.withColumnRenamed(\"id\", \"employee_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7db73cf8-c0fd-4f25-852e-a00e873fb0a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+------------+--------+\n|employee_id|    name|age|salary|     address| nominee|\n+-----------+--------+---+------+------------+--------+\n|          1|  Manish| 26| 75000|       bihar|nominee1|\n|          2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|          3|  Pritam| 22|150000|   Bangalore|   India|\n|          4|Prantosh| 17|200000|     Kolkata|   India|\n|          5|  Vikash| 31|300000|        null|nominee5|\n+-----------+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "new_employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34274b61-ce1e-4720-ac84-f33efe297ccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[63]: <bound method DataFrame.printSchema of DataFrame[id: string, name: string, age: string, salary: string, address: string, nominee: string]>"
     ]
    }
   ],
   "source": [
    "employee_df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e89e00e6-652d-4aa4-870d-067cd9e5db14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Casting datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d86f254e-b677-491d-b639-3210ebdc1f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- salary: string (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.withColumn(\"id\", expr(\"id\").cast(\"string\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5986db8-71fa-4cdc-85b1-19b383aaa3b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.withColumn(\"id\", expr(\"id\").cast(\"string\"))\\\n",
    "    .withColumn(\"salary\", expr(\"salary\").cast(\"long\"))\\\n",
    "    .printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "534fbca8-4e77-46f4-9133-7eee3c74670b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------------+--------+\n|age|salary|     address| nominee|\n+---+------+------------+--------+\n| 26| 75000|       bihar|nominee1|\n| 23|100000|uttarpradesh|nominee2|\n| 22|150000|   Bangalore|   India|\n| 17|200000|     Kolkata|   India|\n| 31|300000|        null|nominee5|\n+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.drop(\"name\", col(\"id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c299877f-4c61-46f9-bb6e-7f7d22711577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9f0947b-78a3-4a4b-b7ed-19e9174a2ec7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+\n| id|    name|age|salary|address|nominee|\n+---+--------+---+------+-------+-------+\n|  4|Prantosh| 17|200000|Kolkata|  India|\n+---+--------+---+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88cb5989-456e-4773-9f77-4b297f4e92d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+---------+\n| id|    name|age|salary|address|nominee|last_name|\n+---+--------+---+------+-------+-------+---------+\n|  4|Prantosh| 17|200000|Kolkata|  India|    kumar|\n+---+--------+---+------+-------+-------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e0e72c7-6d98-4415-ad43-10629248ebf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+---------+-------------+\n| id|    name|age|salary|address|nominee|last_name|    full_name|\n+---+--------+---+------+-------+-------+---------+-------------+\n|  4|Prantosh| 17|200000|Kolkata|  India|    kumar|Prantoshkumar|\n+---+--------+---+------+-------+-------+---------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name, concat(name, last_name) as full_name\n",
    "          from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b8d9b7-44bd-45bc-ab49-00ce3e99938b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+---------+-------------+---+\n| id|    name|age|salary|address|nominee|last_name|    full_name| id|\n+---+--------+---+------+-------+-------+---------+-------------+---+\n|  4|Prantosh| 17|200000|Kolkata|  India|    kumar|Prantoshkumar|  4|\n+---+--------+---+------+-------+-------+---------+-------------+---+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name, concat(name, last_name) as full_name, cast(id as string)\n",
    "          from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023456d6-7406-41ed-9c0f-1724034cca3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[78]: <bound method DataFrame.printSchema of DataFrame[id: string, name: string, age: string, salary: string, address: string, nominee: string, last_name: string, full_name: string, id: string]>"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name, concat(name, last_name) as full_name, cast(id as string)\n",
    "          from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1841b31f-db21-46a4-b934-77304a4f2c6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Union and Union All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78eb50ea-7daf-4c82-9500-6a38a264082f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data=[(10 ,'Anil',50000, 18),\n",
    "(11 ,'Vikas',75000,  16),\n",
    "(12 ,'Nisha',40000,  18),\n",
    "(13 ,'Nidhi',60000,  17),\n",
    "(14 ,'Priya',80000,  18),\n",
    "(15 ,'Mohit',45000,  18),\n",
    "(16 ,'Rajesh',90000, 10),\n",
    "(17 ,'Raman',55000, 16),\n",
    "(18 ,'Sam',65000,   17)]\n",
    "\n",
    "schema = ['id', 'name', 'salary', 'manager_id']\n",
    "\n",
    "manager_df = spark.createDataFrame(data=data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755ccacc-6415-4bb1-af59-636aacf80d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8418bf37-4314-44e0-ae8a-5bd09b68aa29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+----------+\n| id| name|salary|manager_id|\n+---+-----+------+----------+\n| 19|Sohan| 50000|        18|\n| 20| Sima| 75000|        17|\n+---+-----+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "data1=[(19 ,'Sohan',50000, 18),\n",
    "(20 ,'Sima',75000,  17)]\n",
    "\n",
    "schema1 = ['id', 'name', 'salary', 'manager_id']\n",
    "\n",
    "manager_df1 = spark.createDataFrame(data=data1, schema=schema1)\n",
    "\n",
    "manager_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f621b4-54c5-475f-ba01-01532c58bf7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 19| Sohan| 50000|        18|\n| 20|  Sima| 75000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.union(manager_df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ccbda67-b0e1-4335-b2ae-fd60edef1f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[86]: 11"
     ]
    }
   ],
   "source": [
    "manager_df.union(manager_df1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f3f027-c212-426c-8cba-3a395bd8314e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 19| Sohan| 50000|        18|\n| 20|  Sima| 75000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.unionAll(manager_df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b96617a-4f54-4cf1-ad60-5ecac64d6f2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 18|   Sam| 55000|        17|\n| 18|   Sam| 65000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "duplicate_data=[(10 ,'Anil',50000, 18),\n",
    "(11 ,'Vikas',75000,  16),\n",
    "(12 ,'Nisha',40000,  18),\n",
    "(13 ,'Nidhi',60000,  17),\n",
    "(14 ,'Priya',80000,  18),\n",
    "(15 ,'Mohit',45000,  18),\n",
    "(16 ,'Rajesh',90000, 10),\n",
    "(17 ,'Raman',55000, 16),\n",
    "(18 ,'Sam',65000,   17),\n",
    "(18 ,'Sam',55000,   17),\n",
    "(18 ,'Sam',65000,   17)]\n",
    "\n",
    "duplicate_schema = ['id', 'name', 'salary', 'manager_id']\n",
    "\n",
    "duplicate_manager_df = spark.createDataFrame(data=duplicate_data, schema=duplicate_schema)\n",
    "\n",
    "duplicate_manager_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b28e5134-0e98-4eba-a056-cc8767808cb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 18|   Sam| 55000|        17|\n| 18|   Sam| 65000|        17|\n| 19| Sohan| 50000|        18|\n| 20|  Sima| 75000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "duplicate_manager_df.union(manager_df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b39ba2e3-41de-4544-b9fe-c24f1ce1e7c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[91]: 13"
     ]
    }
   ],
   "source": [
    "duplicate_manager_df.union(manager_df1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f29288b-187b-439c-9ebe-d3d4469f17ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 18|   Sam| 55000|        17|\n| 18|   Sam| 65000|        17|\n| 19| Sohan| 50000|        18|\n| 20|  Sima| 75000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "duplicate_manager_df.unionAll(manager_df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d12a084-6ef9-4083-b5aa-cc10401110d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[93]: 13"
     ]
    }
   ],
   "source": [
    "duplicate_manager_df.unionAll(manager_df1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "797bbf33-b80e-4275-964e-16b4c6d5950d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "duplicate_manager_df.createOrReplaceTempView(\"duplicate_manager_tbl\")\n",
    "manager_df1.createOrReplaceTempView(\"manager_df1_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d6f688-0858-46d6-a1da-3675f01eb5c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 18|   Sam| 55000|        17|\n| 18|   Sam| 65000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from duplicate_manager_tbl\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69039d80-7b7d-4399-b297-56d02bb108da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+----------+\n| id| name|salary|manager_id|\n+---+-----+------+----------+\n| 19|Sohan| 50000|        18|\n| 20| Sima| 75000|        17|\n+---+-----+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from manager_df1_tbl\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46d996b8-ec55-47fb-9feb-5c08e94b91ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[99]: 12"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from duplicate_manager_tbl\n",
    "          union\n",
    "          select * from manager_df1_tbl\n",
    "          \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "168ac1be-da6f-45a8-86d8-25a05f1244c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[101]: 13"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from duplicate_manager_tbl\n",
    "          union all\n",
    "          select * from manager_df1_tbl\n",
    "          \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a06b50a1-d779-4bd6-be01-1f3082a93531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[102]: 22"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from duplicate_manager_tbl\n",
    "          union all\n",
    "          select * from duplicate_manager_tbl\n",
    "          \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aba2557-a22b-4655-aae4-d649b714b292",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[103]: 10"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from duplicate_manager_tbl\n",
    "          union\n",
    "          select * from duplicate_manager_tbl\n",
    "          \"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59190869-c4ec-4f18-81d0-95a1855294e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----+\n| id|salary|manager_id| name|\n+---+------+----------+-----+\n| 19| 50000|        18|Sohan|\n| 20| 75000|        17| Sima|\n+---+------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "wrong_column_data=[(19 ,50000, 18,'Sohan'),\n",
    "(20 ,75000,  17,'Sima')]\n",
    "\n",
    "wrong_column_schema = ['id', 'salary', 'manager_id', 'name']\n",
    "\n",
    "wrong_column_df = spark.createDataFrame(data=wrong_column_data, schema=wrong_column_schema)\n",
    "\n",
    "wrong_column_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3061a0a-b10e-464f-a142-5df3ae45b366",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+----------+\n| id| name|salary|manager_id|\n+---+-----+------+----------+\n| 19|Sohan| 50000|        18|\n| 20| Sima| 75000|        17|\n| 19|50000|    18|     Sohan|\n| 20|75000|    17|      Sima|\n+---+-----+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df1.union(wrong_column_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ad05828-f360-416d-a696-da5024a4062f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+----------+\n| id| name|salary|manager_id|\n+---+-----+------+----------+\n| 19|Sohan| 50000|        18|\n| 20| Sima| 75000|        17|\n| 19|Sohan| 50000|        18|\n| 20| Sima| 75000|        17|\n+---+-----+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df1.unionByName(wrong_column_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ef7ec79-9515-4e43-bea7-7c61b7722230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----+-----+\n| id|salary|manager_id| name|bonus|\n+---+------+----------+-----+-----+\n| 19| 50000|        18|Sohan|   10|\n| 20| 75000|        17| Sima|   20|\n+---+------+----------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "wrong_columns=[(19 ,50000, 18,'Sohan',10),\n",
    "(20 ,75000,  17,'Sima',20)]\n",
    "\n",
    "wrong_schema = ['id', 'salary', 'manager_id', 'name', 'bonus']\n",
    "\n",
    "wrong_manager_df = spark.createDataFrame(data=wrong_columns, schema=wrong_schema)\n",
    "\n",
    "wrong_manager_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a51ea558-bc45-43f0-9f52-70353573659f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4341238895431347>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mwrong_manager_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmanager_df1\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3646\u001B[0m, in \u001B[0;36mDataFrame.union\u001B[0;34m(self, other)\u001B[0m\n",
       "\u001B[1;32m   3598\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munion\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m   3599\u001B[0m     \u001B[38;5;124;03m\"\"\"Return a new :class:`DataFrame` containing union of rows in this and another\u001B[39;00m\n",
       "\u001B[1;32m   3600\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   3601\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3644\u001B[0m \u001B[38;5;124;03m    +----+----+----+\u001B[39;00m\n",
       "\u001B[1;32m   3645\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3646\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 5 columns and the second input has 4 columns.;\n",
       "'Union false, false\n",
       ":- LogicalRDD [id#3135L, salary#3136L, manager_id#3137L, name#3138, bonus#3139L], false\n",
       "+- LogicalRDD [id#2523L, name#2524, salary#2525L, manager_id#2526L], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-4341238895431347>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mwrong_manager_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmanager_df1\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3646\u001B[0m, in \u001B[0;36mDataFrame.union\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m   3598\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munion\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   3599\u001B[0m     \u001B[38;5;124;03m\"\"\"Return a new :class:`DataFrame` containing union of rows in this and another\u001B[39;00m\n\u001B[1;32m   3600\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   3601\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3644\u001B[0m \u001B[38;5;124;03m    +----+----+----+\u001B[39;00m\n\u001B[1;32m   3645\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3646\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 5 columns and the second input has 4 columns.;\n'Union false, false\n:- LogicalRDD [id#3135L, salary#3136L, manager_id#3137L, name#3138, bonus#3139L], false\n+- LogicalRDD [id#2523L, name#2524, salary#2525L, manager_id#2526L], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [NUM_COLUMNS_MISMATCH] UNION can only be performed on inputs with the same number of columns, but the first input has 5 columns and the second input has 4 columns.;\n'Union false, false\n:- LogicalRDD [id#3135L, salary#3136L, manager_id#3137L, name#3138, bonus#3139L], false\n+- LogicalRDD [id#2523L, name#2524, salary#2525L, manager_id#2526L], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_manager_df.union(manager_df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a242e2af-0e6d-42ec-84fb-2870b9201a05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----+\n| id|salary|manager_id| name|\n+---+------+----------+-----+\n| 19| 50000|        18|Sohan|\n| 20| 75000|        17| Sima|\n| 19| Sohan|     50000|   18|\n| 20|  Sima|     75000|   17|\n+---+------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wrong_manager_df.select('id', 'salary', 'manager_id', 'name').union(manager_df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ed1ca68-1bd9-47a0-9cac-fc63d52669b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----+\n| id|salary|manager_id|  nam|\n+---+------+----------+-----+\n| 19| 50000|        18|Sohan|\n| 20| 75000|        17| Sima|\n+---+------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "wrong_column_data2=[(19 ,50000, 18,'Sohan'),\n",
    "(20 ,75000,  17,'Sima')]\n",
    "\n",
    "wrong_column_schema2 = ['id', 'salary', 'manager_id', 'nam']\n",
    "\n",
    "wrong_column_df2 = spark.createDataFrame(data=wrong_column_data2, schema=wrong_column_schema2)\n",
    "\n",
    "wrong_column_df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f609f0-542f-449c-9cc1-07baf9eb65ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4341238895431350>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mwrong_manager_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munionByName\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrong_column_df2\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3738\u001B[0m, in \u001B[0;36mDataFrame.unionByName\u001B[0;34m(self, other, allowMissingColumns)\u001B[0m\n",
       "\u001B[1;32m   3682\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munionByName\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m, allowMissingColumns: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m   3683\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns a new :class:`DataFrame` containing union of rows in this and another\u001B[39;00m\n",
       "\u001B[1;32m   3684\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   3685\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3736\u001B[0m \u001B[38;5;124;03m    +----+----+----+----+\u001B[39;00m\n",
       "\u001B[1;32m   3737\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munionByName\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowMissingColumns\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: Cannot resolve column name \"name\" among (id, salary, manager_id, nam)."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-4341238895431350>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mwrong_manager_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munionByName\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrong_column_df2\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3738\u001B[0m, in \u001B[0;36mDataFrame.unionByName\u001B[0;34m(self, other, allowMissingColumns)\u001B[0m\n\u001B[1;32m   3682\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munionByName\u001B[39m(\u001B[38;5;28mself\u001B[39m, other: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m, allowMissingColumns: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   3683\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns a new :class:`DataFrame` containing union of rows in this and another\u001B[39;00m\n\u001B[1;32m   3684\u001B[0m \u001B[38;5;124;03m    :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   3685\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3736\u001B[0m \u001B[38;5;124;03m    +----+----+----+----+\u001B[39;00m\n\u001B[1;32m   3737\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3738\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munionByName\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowMissingColumns\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: Cannot resolve column name \"name\" among (id, salary, manager_id, nam).",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: Cannot resolve column name \"name\" among (id, salary, manager_id, nam).",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_manager_df.unionByName(wrong_column_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bacdedc8-05c4-4a4a-aa77-1a1a5b071e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Casewhen and otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce17407e-f468-46f9-b072-cfd0f2b40573",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+\n|  id|   name| age|salary|country|       dept|\n+----+-------+----+------+-------+-----------+\n|   1| manish|  26| 20000|  india|         IT|\n|   2|  rahul|null| 40000|germany|engineering|\n|   3|  pawan|  12| 60000|  india|      sales|\n|   4|roshini|  44|  null|     uk|engineering|\n|   5|raushan|  35| 70000|  india|      sales|\n|   6|   null|  29|200000|     uk|         IT|\n|   7|   adam|  37| 65000|     us|         IT|\n|   8|  chris|  16| 40000|     us|      sales|\n|null|   null|null|  null|   null|       null|\n|   7|   adam|  37| 65000|     us|         IT|\n+----+-------+----+------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_data = [\n",
    "(1,'manish',26,20000,'india','IT'),\n",
    "(2,'rahul',None,40000,'germany','engineering'),\n",
    "(3,'pawan',12,60000,'india','sales'),\n",
    "(4,'roshini',44,None,'uk','engineering'),\n",
    "(5,'raushan',35,70000,'india','sales'),\n",
    "(6,None,29,200000,'uk','IT'),\n",
    "(7,'adam',37,65000,'us','IT'),\n",
    "(8,'chris',16,40000,'us','sales'),\n",
    "(None,None,None,None,None,None),\n",
    "(7,'adam',37,65000,'us','IT')\n",
    "]\n",
    "\n",
    "emp_scheme = ['id', 'name', 'age', 'salary', 'country', 'dept']\n",
    "\n",
    "emp_df = spark.createDataFrame(data=emp_data, schema=emp_scheme)\n",
    "\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13e6b33a-98bb-481a-8962-d123f224700f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+--------+\n|  id|   name| age|salary|country|       dept|   adult|\n+----+-------+----+------+-------+-----------+--------+\n|   1| manish|  26| 20000|  india|         IT|     Yes|\n|   2|  rahul|null| 40000|germany|engineering|No value|\n|   3|  pawan|  12| 60000|  india|      sales|      No|\n|   4|roshini|  44|  null|     uk|engineering|     Yes|\n|   5|raushan|  35| 70000|  india|      sales|     Yes|\n|   6|   null|  29|200000|     uk|         IT|     Yes|\n|   7|   adam|  37| 65000|     us|         IT|     Yes|\n|   8|  chris|  16| 40000|     us|      sales|      No|\n|null|   null|null|  null|   null|       null|No value|\n|   7|   adam|  37| 65000|     us|         IT|     Yes|\n+----+-------+----+------+-------+-----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.withColumn(\"adult\", when(col(\"age\")>18, \"Yes\")\n",
    "                  .when(col(\"age\")<18, \"No\")\n",
    "                  .otherwise(\"No value\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e60352a-6e30-4207-8345-24138639f55f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+------+-------+-----------+-----+\n|  id|   name|age|salary|country|       dept|adult|\n+----+-------+---+------+-------+-----------+-----+\n|   1| manish| 26| 20000|  india|         IT|  Yes|\n|   2|  rahul| 19| 40000|germany|engineering|  Yes|\n|   3|  pawan| 12| 60000|  india|      sales|   No|\n|   4|roshini| 44|  null|     uk|engineering|  Yes|\n|   5|raushan| 35| 70000|  india|      sales|  Yes|\n|   6|   null| 29|200000|     uk|         IT|  Yes|\n|   7|   adam| 37| 65000|     us|         IT|  Yes|\n|   8|  chris| 16| 40000|     us|      sales|   No|\n|null|   null| 19|  null|   null|       null|  Yes|\n|   7|   adam| 37| 65000|     us|         IT|  Yes|\n+----+-------+---+------+-------+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.withColumn(\"age\", when(col(\"age\").isNull(), lit(19))\n",
    "                  .otherwise(col(\"age\")))\\\n",
    "    .withColumn(\"adult\", when(col(\"age\")>18, \"Yes\")\n",
    "                  .when(col(\"age\")<18, \"No\")\n",
    "                  .otherwise(\"No value\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73706620-9d92-455b-9893-83c3e47c6f90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+--------+\n|  id|   name| age|salary|country|       dept|age_wise|\n+----+-------+----+------+-------+-----------+--------+\n|   1| manish|  26| 20000|  india|         IT|   Major|\n|   2|  rahul|null| 40000|germany|engineering|   Major|\n|   3|  pawan|  12| 60000|  india|      sales|   Minor|\n|   4|roshini|  44|  null|     uk|engineering|   Major|\n|   5|raushan|  35| 70000|  india|      sales|   Major|\n|   6|   null|  29|200000|     uk|         IT|   Major|\n|   7|   adam|  37| 65000|     us|         IT|   Major|\n|   8|  chris|  16| 40000|     us|      sales|   Minor|\n|null|   null|null|  null|   null|       null|   Major|\n|   7|   adam|  37| 65000|     us|         IT|   Major|\n+----+-------+----+------+-------+-----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.withColumn(\"age_wise\", when((col(\"age\") < 18) & (col(\"age\") > 0), \"Minor\")\n",
    "                  .otherwise(\"Major\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de04cc24-1bc2-4da7-b0ce-6314b71e6c56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df.createOrReplaceTempView(\"emp_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23e3353d-ebeb-4587-b77a-d4667189c918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+--------+\n|  id|   name| age|salary|country|       dept|   adult|\n+----+-------+----+------+-------+-----------+--------+\n|   1| manish|  26| 20000|  india|         IT|   major|\n|   2|  rahul|null| 40000|germany|engineering|no value|\n|   3|  pawan|  12| 60000|  india|      sales|   minor|\n|   4|roshini|  44|  null|     uk|engineering|   major|\n|   5|raushan|  35| 70000|  india|      sales|   major|\n|   6|   null|  29|200000|     uk|         IT|   major|\n|   7|   adam|  37| 65000|     us|         IT|   major|\n|   8|  chris|  16| 40000|     us|      sales|   minor|\n|null|   null|null|  null|   null|       null|no value|\n|   7|   adam|  37| 65000|     us|         IT|   major|\n+----+-------+----+------+-------+-----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * ,\n",
    "          case when age > 18 then \"major\"\n",
    "          when age < 18 then \"minor\"\n",
    "          else \"no value\"\n",
    "          end as adult\n",
    "          from emp_tbl\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "883a92fb-9833-4902-a81b-a14ee5825008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Unique and Sorted records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f78b37e1-cf0a-4c1b-b442-7737578eb81c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 15| Mohit| 45000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 90000|        18|\n| 18|   Sam| 65000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_data=[(10 ,'Anil',50000, 18),\n",
    "(11 ,'Vikas',75000,  16),\n",
    "(12 ,'Nisha',40000,  18),\n",
    "(13 ,'Nidhi',60000,  17),\n",
    "(14 ,'Priya',80000,  18),\n",
    "(15 ,'Mohit',45000,  18),\n",
    "(16 ,'Rajesh',90000, 10),\n",
    "(17 ,'Raman',55000, 16),\n",
    "(18 ,'Sam',65000,   17),\n",
    "(15 ,'Mohit',45000,  18),\n",
    "(13 ,'Nidhi',60000,  17),      \n",
    "(14 ,'Priya',90000,  18),  \n",
    "(18 ,'Sam',65000,   17)\n",
    "     ]\n",
    "\n",
    "manager_scheme = ['id', 'name', 'salary', 'manager_id']\n",
    "\n",
    "managerdf = spark.createDataFrame(data=manager_data, schema=manager_scheme)\n",
    "\n",
    "managerdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add1fcbc-ca6a-43ca-bf80-a061622f8f0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "managerdf.createOrReplaceGlobalTempView(\"managerdf_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13a4cd1b-2ad9-46d3-93b5-9b6e6fa8cac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 12| Nisha| 40000|        18|\n| 11| Vikas| 75000|        16|\n| 13| Nidhi| 60000|        17|\n| 15| Mohit| 45000|        18|\n| 14| Priya| 80000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 14| Priya| 90000|        18|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "managerdf.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca511d7-bc2c-45d7-9c99-9353f154e186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[125]: 10"
     ]
    }
   ],
   "source": [
    "managerdf.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a85c28dd-0a6f-4385-b186-441cbe6fbc78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 11| Vikas| 75000|        16|\n| 12| Nisha| 40000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 80000|        18|\n| 15| Mohit| 45000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 15| Mohit| 45000|        18|\n| 13| Nidhi| 60000|        17|\n| 14| Priya| 90000|        18|\n| 18|   Sam| 65000|        17|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "managerdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0553c6d-fe47-4bd7-a4e0-e947a8ad3895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-281393194693269>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mmanagerdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistinct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshow\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: distinct() takes 1 positional argument but 3 were given"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-281393194693269>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmanagerdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistinct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshow\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\n\u001B[0;31mTypeError\u001B[0m: distinct() takes 1 positional argument but 3 were given",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: distinct() takes 1 positional argument but 3 were given",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "managerdf.distinct(\"id\", \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd88e174-ae8a-462c-a767-5ca10b90b12c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n| id|  name|\n+---+------+\n| 10|  Anil|\n| 11| Vikas|\n| 12| Nisha|\n| 13| Nidhi|\n| 15| Mohit|\n| 14| Priya|\n| 17| Raman|\n| 16|Rajesh|\n| 18|   Sam|\n+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "managerdf.select(\"id\", \"name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05b7599c-6cac-476c-aa18-e8a82390f3f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 10|  Anil| 50000|        18|\n| 12| Nisha| 40000|        18|\n| 11| Vikas| 75000|        16|\n| 13| Nidhi| 60000|        17|\n| 15| Mohit| 45000|        18|\n| 14| Priya| 80000|        18|\n| 16|Rajesh| 90000|        10|\n| 17| Raman| 55000|        16|\n| 18|   Sam| 65000|        17|\n| 14| Priya| 90000|        18|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "drop_dup_df = managerdf.drop_duplicates(['id', 'name', 'salary', 'manager_id']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58b0dc89-f595-4181-a3a3-cb8b4907d906",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 12| Nisha| 40000|        18|\n| 15| Mohit| 45000|        18|\n| 15| Mohit| 45000|        18|\n| 10|  Anil| 50000|        18|\n| 17| Raman| 55000|        16|\n| 13| Nidhi| 60000|        17|\n| 13| Nidhi| 60000|        17|\n| 18|   Sam| 65000|        17|\n| 18|   Sam| 65000|        17|\n| 11| Vikas| 75000|        16|\n| 14| Priya| 80000|        18|\n| 16|Rajesh| 90000|        10|\n| 14| Priya| 90000|        18|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "managerdf.sort(col(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d55e3b1-3a63-4fc7-bb6f-38e9e4c2162b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 14| Priya| 90000|        18|\n| 16|Rajesh| 90000|        10|\n| 14| Priya| 80000|        18|\n| 11| Vikas| 75000|        16|\n| 18|   Sam| 65000|        17|\n| 18|   Sam| 65000|        17|\n| 13| Nidhi| 60000|        17|\n| 13| Nidhi| 60000|        17|\n| 17| Raman| 55000|        16|\n| 10|  Anil| 50000|        18|\n| 15| Mohit| 45000|        18|\n| 15| Mohit| 45000|        18|\n| 12| Nisha| 40000|        18|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "managerdf.sort(col(\"salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76b38b9a-a8b6-49f0-b39a-b0601f1f921a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n| id|  name|salary|manager_id|\n+---+------+------+----------+\n| 16|Rajesh| 90000|        10|\n| 14| Priya| 90000|        18|\n| 14| Priya| 80000|        18|\n| 11| Vikas| 75000|        16|\n| 18|   Sam| 65000|        17|\n| 18|   Sam| 65000|        17|\n| 13| Nidhi| 60000|        17|\n| 13| Nidhi| 60000|        17|\n| 17| Raman| 55000|        16|\n| 10|  Anil| 50000|        18|\n| 15| Mohit| 45000|        18|\n| 15| Mohit| 45000|        18|\n| 12| Nisha| 40000|        18|\n+---+------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "managerdf.sort(col(\"salary\").desc(), col(\"name\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e528265-2b3d-4735-b8a3-8e88411c1d01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------+\n| id|name|referee_id|\n+---+----+----------+\n|  1|Will|      null|\n|  2|Jane|      null|\n|  3|Alex|         2|\n|  4|Bill|      null|\n|  5|Zack|         1|\n|  6|Mark|         2|\n+---+----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "leet_code_data = [\n",
    "    (1, 'Will', None),\n",
    "    (2, 'Jane', None),\n",
    "    (3, 'Alex', 2),\n",
    "    (4, 'Bill', None),\n",
    "    (5, 'Zack', 1),\n",
    "    (6, 'Mark', 2)\n",
    "]\n",
    "\n",
    "leet_schema = ['id', 'name', 'referee_id']\n",
    "\n",
    "leet_df = spark.createDataFrame(data=leet_code_data, schema=leet_schema)\n",
    "\n",
    "leet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83e14099-0d19-4dc4-8601-b2ec8a97c822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "leet_df.createOrReplaceTempView(\"leet_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "799589c7-7d07-4abc-afa9-5efdc90fcf97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Leet Code \n",
    "Get the names whose referee id is not 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a000ef2-206c-48eb-b56f-f8b117d58080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n|name|\n+----+\n|Will|\n|Jane|\n|Bill|\n|Zack|\n+----+\n\n"
     ]
    }
   ],
   "source": [
    "leet_df.select(\"name\").where((col(\"referee_id\") != 2) | (col(\"referee_id\")).isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2d2c468-950c-4d92-a841-3f8d3a6363d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n|name|\n+----+\n|Will|\n|Jane|\n|Bill|\n|Zack|\n+----+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select name \n",
    "          from leet_tbl\n",
    "          where referee_id != 2 or referee_id is null\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51543de6-fdac-4c5c-ace3-25f505a72619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62e303c7-6d1d-4075-92a7-c386e3925d78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[155]: 10"
     ]
    }
   ],
   "source": [
    "emp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c1de75-9ccb-48d9-8672-b5e361db9739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[158]: 10"
     ]
    }
   ],
   "source": [
    "emp_df.select(\"name\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ed7fc0-299b-44c7-b4f7-11c2bb854c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n|count(id)|\n+---------+\n|        9|\n+---------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(count(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69f2e972-4739-4903-bed4-c14818be3aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-------------+--------------+---------------+\n|total_salary|highest_salary|lowest_salary|average_salary|count_of_salary|\n+------------+--------------+-------------+--------------+---------------+\n|      560000|        200000|        20000|         70000|              8|\n+------------+--------------+-------------+--------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(sum(\"salary\").alias(\"total_salary\"), max(\"salary\").alias(\"highest_salary\"), min(\"salary\").alias(\"lowest_salary\"),\n",
    "              avg(\"salary\").alias(\"average_salary\").cast(\"int\"), count(\"salary\").alias(\"count_of_salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1959617-2348-4cd7-95f5-874189d9b223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b625d084-7d52-405c-adbb-8d7c4cc3ead7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+\n| id|   name|salary|     dept|\n+---+-------+------+---------+\n|  1| manish| 50000|       IT|\n|  2| vikash| 60000|    sales|\n|  3|raushan| 70000|marketing|\n|  4| mukesh| 80000|       IT|\n|  5| pritam| 90000|    sales|\n|  6| nikita| 45000|marketing|\n|  7| ragini| 55000|marketing|\n|  8| rakesh|100000|       IT|\n|  9| aditya| 65000|       IT|\n| 10|  rahul| 50000|marketing|\n+---+-------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "empp_data = [(1,'manish',50000,'IT'),\n",
    "(2,'vikash',60000,'sales'),\n",
    "(3,'raushan',70000,'marketing'),\n",
    "(4,'mukesh',80000,'IT'),\n",
    "(5,'pritam',90000,'sales'),\n",
    "(6,'nikita',45000,'marketing'),\n",
    "(7,'ragini',55000,'marketing'),\n",
    "(8,'rakesh',100000,'IT'),\n",
    "(9,'aditya',65000,'IT'),\n",
    "(10,'rahul',50000,'marketing')]\n",
    "\n",
    "empp_schema =  ['id', 'name', 'salary', 'dept']\n",
    "\n",
    "empp_df = spark.createDataFrame(data=empp_data, schema=empp_schema)\n",
    "\n",
    "empp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37023a28-a15f-4e2d-a649-4d9b1dc40297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n|     dept|sum(salary)|\n+---------+-----------+\n|       IT|     295000|\n|    sales|     150000|\n|marketing|     220000|\n+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "empp_df.groupBy(\"dept\").sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ac9cb1-91f5-4c29-8541-38970db3369a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+-------+\n| id|   name|salary|     dept|country|\n+---+-------+------+---------+-------+\n|  1| manish| 50000|       IT|  india|\n|  2| vikash| 60000|    sales|     us|\n|  3|raushan| 70000|marketing|  india|\n|  4| mukesh| 80000|       IT|     us|\n|  5| pritam| 90000|    sales|  india|\n|  6| nikita| 45000|marketing|     us|\n|  7| ragini| 55000|marketing|  india|\n|  8| rakesh|100000|       IT|     us|\n|  9| aditya| 65000|       IT|  india|\n| 10|  rahul| 50000|marketing|     us|\n+---+-------+------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "empl_data =[(1,'manish',50000,'IT','india'),\n",
    "(2,'vikash',60000,'sales','us'),\n",
    "(3,'raushan',70000,'marketing','india'),\n",
    "(4,'mukesh',80000,'IT','us'),\n",
    "(5,'pritam',90000,'sales','india'),\n",
    "(6,'nikita',45000,'marketing','us'),\n",
    "(7,'ragini',55000,'marketing','india'),\n",
    "(8,'rakesh',100000,'IT','us'),\n",
    "(9,'aditya',65000,'IT','india'),\n",
    "(10,'rahul',50000,'marketing','us')\n",
    "]\n",
    "\n",
    "empl_schema =  ['id', 'name', 'salary', 'dept', 'country']\n",
    "\n",
    "empl_df = spark.createDataFrame(data=empl_data, schema=empl_schema)\n",
    "\n",
    "empl_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba6b0c87-81b8-4d75-b751-525d2700a105",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "empl_df.createOrReplaceTempView(\"empl_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26f03e0d-3bb5-42d7-aadb-a144464fd885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----------+\n|     dept|country|sum(salary)|\n+---------+-------+-----------+\n|       IT|  india|     115000|\n|    sales|     us|      60000|\n|marketing|  india|     125000|\n|    sales|  india|      90000|\n|       IT|     us|     180000|\n|marketing|     us|      95000|\n+---------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "empl_df.groupBy(\"dept\", \"country\").agg(sum(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8c8067-760f-464b-b43d-41b7cec03c92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n|     dept|sum(salary)|\n+---------+-----------+\n|       IT|     295000|\n|    sales|     150000|\n|marketing|     220000|\n+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select dept, sum(salary)\n",
    "          from empl_tbl\n",
    "          group by dept\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bea563a-4bbe-45de-824d-65fde1ee6e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9218093f-9893-44b5-b064-5cf2aae1fab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+\n|customer_id|customer_name|address|date_of_joining|\n+-----------+-------------+-------+---------------+\n|          1|       manish|  patna|     30-05-2022|\n|          2|       vikash|kolkata|     12-03-2023|\n|          3|       nikita|  delhi|     25-06-2023|\n|          4|        rahul| ranchi|     24-03-2023|\n|          5|       mahesh| jaipur|     22-03-2023|\n|          6|     prantosh|kolkata|     18-10-2022|\n|          7|        raman|  patna|     30-12-2022|\n|          8|      prakash| ranchi|     24-02-2023|\n|          9|       ragini|kolkata|     03-03-2023|\n|         10|      raushan| jaipur|     05-02-2023|\n+-----------+-------------+-------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_data = [(1,'manish','patna',\"30-05-2022\"),\n",
    "(2,'vikash','kolkata',\"12-03-2023\"),\n",
    "(3,'nikita','delhi',\"25-06-2023\"),\n",
    "(4,'rahul','ranchi',\"24-03-2023\"),\n",
    "(5,'mahesh','jaipur',\"22-03-2023\"),\n",
    "(6,'prantosh','kolkata',\"18-10-2022\"),\n",
    "(7,'raman','patna',\"30-12-2022\"),\n",
    "(8,'prakash','ranchi',\"24-02-2023\"),\n",
    "(9,'ragini','kolkata',\"03-03-2023\"),\n",
    "(10,'raushan','jaipur',\"05-02-2023\")]\n",
    "\n",
    "customer_schema=['customer_id','customer_name','address','date_of_joining']\n",
    "\n",
    "customer_df = spark.createDataFrame(data=customer_data, schema=customer_schema)\n",
    "\n",
    "customer_df.createOrReplaceTempView(\"customer_tbl\")\n",
    "\n",
    "customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fc75d84-13d0-4e61-a4e1-9a70c93ae263",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------------+\n|customer_id|product_id|quantity|date_of_purchase|\n+-----------+----------+--------+----------------+\n|          1|        22|      10|      01-06-2022|\n|          1|        27|       5|      03-02-2023|\n|          2|         5|       3|      01-06-2023|\n|          5|        22|       1|      22-03-2023|\n|          7|        22|       4|      03-02-2023|\n|          9|         5|       6|      03-03-2023|\n|          2|         1|      12|      15-06-2023|\n|          1|        56|       2|      25-06-2023|\n|          5|        12|       5|      15-04-2023|\n|         11|        12|      76|      12-03-2023|\n+-----------+----------+--------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "sales_data = [(1,22,10,\"01-06-2022\"),\n",
    "(1,27,5,\"03-02-2023\"),\n",
    "(2,5,3,\"01-06-2023\"),\n",
    "(5,22,1,\"22-03-2023\"),\n",
    "(7,22,4,\"03-02-2023\"),\n",
    "(9,5,6,\"03-03-2023\"),\n",
    "(2,1,12,\"15-06-2023\"),\n",
    "(1,56,2,\"25-06-2023\"),\n",
    "(5,12,5,\"15-04-2023\"),\n",
    "(11,12,76,\"12-03-2023\")]\n",
    "\n",
    "sales_schema=['customer_id','product_id','quantity','date_of_purchase']\n",
    "\n",
    "\n",
    "sales_df = spark.createDataFrame(data=sales_data, schema=sales_schema)\n",
    "\n",
    "sales_df.createOrReplaceTempView(\"sales_tbl\")\n",
    "\n",
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a872925d-39de-4d9c-85c0-c2d3ceba445f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n| id|   name|price|\n+---+-------+-----+\n|  1|  fanta|   20|\n|  2|    dew|   22|\n|  5| sprite|   40|\n|  7|redbull|  100|\n| 12|  mazza|   45|\n| 22|   coke|   27|\n| 25|  limca|   21|\n| 27|  pepsi|   14|\n| 56|  sting|   10|\n+---+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "product_data = [(1, 'fanta',20),\n",
    "(2, 'dew',22),\n",
    "(5, 'sprite',40),\n",
    "(7, 'redbull',100),\n",
    "(12,'mazza',45),\n",
    "(22,'coke',27),\n",
    "(25,'limca',21),\n",
    "(27,'pepsi',14),\n",
    "(56,'sting',10)]\n",
    "\n",
    "product_schema=['id','name','price']\n",
    "\n",
    "product_df = spark.createDataFrame(data=product_data, schema=product_schema)\n",
    "\n",
    "product_df.createOrReplaceTempView(\"product_tbl\")\n",
    "\n",
    "product_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "066c6322-0a84-4b86-b6ef-4c45342a4272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|customer_id|customer_name|address|date_of_joining|customer_id|product_id|quantity|date_of_purchase|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|          1|       manish|  patna|     30-05-2022|          1|        22|      10|      01-06-2022|\n|          1|       manish|  patna|     30-05-2022|          1|        27|       5|      03-02-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        56|       2|      25-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         5|       3|      01-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         1|      12|      15-06-2023|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        22|       1|      22-03-2023|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        12|       5|      15-04-2023|\n|          7|        raman|  patna|     30-12-2022|          7|        22|       4|      03-02-2023|\n|          9|       ragini|kolkata|     03-03-2023|          9|         5|       6|      03-03-2023|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "customer_df.join(sales_df, sales_df[\"customer_id\"]==customer_df[\"customer_id\"], \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a01d528-cb24-4d89-97bd-9bcb298987fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|product_id|\n+----------+\n|         1|\n|         5|\n|         5|\n|        12|\n|        22|\n|        22|\n|        22|\n|        27|\n|        56|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "customer_df.join(sales_df, sales_df[\"customer_id\"]==customer_df[\"customer_id\"], \\\n",
    "    \"inner\").select(sales_df['product_id']).sort(sales_df['product_id']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a762f731-33fc-47e7-966e-bf119f7290f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_df.join(sales_df, (sales_df[\"customer_id\"]==customer_df[\"customer_id\"]) & \\\n",
    "                 (sales_df[\"product_id\"]==customer_df[\"product_id\"]), \\\n",
    "    \"inner\").select(sales_df['product_id']).sort(sales_df['product_id']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ea23c93-c78b-4513-978e-32a7d63daf57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|customer_id|customer_name|address|date_of_joining|customer_id|product_id|quantity|date_of_purchase|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|          1|       manish|  patna|     30-05-2022|          1|        56|       2|      25-06-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        27|       5|      03-02-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        22|      10|      01-06-2022|\n|          2|       vikash|kolkata|     12-03-2023|          2|         1|      12|      15-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         5|       3|      01-06-2023|\n|          3|       nikita|  delhi|     25-06-2023|       null|      null|    null|            null|\n|          4|        rahul| ranchi|     24-03-2023|       null|      null|    null|            null|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        12|       5|      15-04-2023|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        22|       1|      22-03-2023|\n|          6|     prantosh|kolkata|     18-10-2022|       null|      null|    null|            null|\n|          7|        raman|  patna|     30-12-2022|          7|        22|       4|      03-02-2023|\n|          8|      prakash| ranchi|     24-02-2023|       null|      null|    null|            null|\n|          9|       ragini|kolkata|     03-03-2023|          9|         5|       6|      03-03-2023|\n|         10|      raushan| jaipur|     05-02-2023|       null|      null|    null|            null|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_df.join(sales_df, sales_df[\"customer_id\"]==customer_df[\"customer_id\"], \"left\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3301d41e-45ca-4de0-be70-78cd7158863a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|customer_id|customer_name|address|date_of_joining|customer_id|product_id|quantity|date_of_purchase|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|          1|       manish|  patna|     30-05-2022|          1|        22|      10|      01-06-2022|\n|          1|       manish|  patna|     30-05-2022|          1|        27|       5|      03-02-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         5|       3|      01-06-2023|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        22|       1|      22-03-2023|\n|          7|        raman|  patna|     30-12-2022|          7|        22|       4|      03-02-2023|\n|          9|       ragini|kolkata|     03-03-2023|          9|         5|       6|      03-03-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         1|      12|      15-06-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        56|       2|      25-06-2023|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        12|       5|      15-04-2023|\n|       null|         null|   null|           null|         11|        12|      76|      12-03-2023|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_df.join(sales_df, sales_df[\"customer_id\"]==customer_df[\"customer_id\"], \"right\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fab409f8-68a1-40f3-a96b-48a123707bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------------+---+-------+-----+\n|customer_id|product_id|quantity|date_of_purchase| id|   name|price|\n+-----------+----------+--------+----------------+---+-------+-----+\n|          2|         1|      12|      15-06-2023|  1|  fanta|   20|\n|       null|      null|    null|            null|  2|    dew|   22|\n|          9|         5|       6|      03-03-2023|  5| sprite|   40|\n|          2|         5|       3|      01-06-2023|  5| sprite|   40|\n|       null|      null|    null|            null|  7|redbull|  100|\n|         11|        12|      76|      12-03-2023| 12|  mazza|   45|\n|          5|        12|       5|      15-04-2023| 12|  mazza|   45|\n|          7|        22|       4|      03-02-2023| 22|   coke|   27|\n|          5|        22|       1|      22-03-2023| 22|   coke|   27|\n|          1|        22|      10|      01-06-2022| 22|   coke|   27|\n|       null|      null|    null|            null| 25|  limca|   21|\n|          1|        27|       5|      03-02-2023| 27|  pepsi|   14|\n|          1|        56|       2|      25-06-2023| 56|  sting|   10|\n+-----------+----------+--------+----------------+---+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_df.join(product_df, sales_df[\"product_id\"]==product_df[\"id\"], \"right\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb9ce0d-1daa-4e27-8c9c-5ef22aa84a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+-----------+----------+--------+----------------+\n|  id|   name|price|customer_id|product_id|quantity|date_of_purchase|\n+----+-------+-----+-----------+----------+--------+----------------+\n|   1|  fanta|   20|          1|        22|      10|      01-06-2022|\n|   1|  fanta|   20|          1|        27|       5|      03-02-2023|\n|   2|    dew|   22|          2|         5|       3|      01-06-2023|\n|   5| sprite|   40|          5|        22|       1|      22-03-2023|\n|   7|redbull|  100|          7|        22|       4|      03-02-2023|\n|null|   null| null|          9|         5|       6|      03-03-2023|\n|   2|    dew|   22|          2|         1|      12|      15-06-2023|\n|   1|  fanta|   20|          1|        56|       2|      25-06-2023|\n|   5| sprite|   40|          5|        12|       5|      15-04-2023|\n|null|   null| null|         11|        12|      76|      12-03-2023|\n+----+-------+-----+-----------+----------+--------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    " \n",
    "product_df.join(sales_df, sales_df[\"customer_id\"]==product_df[\"id\"], \"right\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba08ecd8-ea94-487f-869a-000ceea847d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|customer_id|customer_name|address|date_of_joining|customer_id|product_id|quantity|date_of_purchase|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|          1|       manish|  patna|     30-05-2022|          1|        22|      10|      01-06-2022|\n|          1|       manish|  patna|     30-05-2022|          1|        27|       5|      03-02-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        56|       2|      25-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         5|       3|      01-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         1|      12|      15-06-2023|\n|          3|       nikita|  delhi|     25-06-2023|       null|      null|    null|            null|\n|          4|        rahul| ranchi|     24-03-2023|       null|      null|    null|            null|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        22|       1|      22-03-2023|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        12|       5|      15-04-2023|\n|          6|     prantosh|kolkata|     18-10-2022|       null|      null|    null|            null|\n|          7|        raman|  patna|     30-12-2022|          7|        22|       4|      03-02-2023|\n|          8|      prakash| ranchi|     24-02-2023|       null|      null|    null|            null|\n|          9|       ragini|kolkata|     03-03-2023|          9|         5|       6|      03-03-2023|\n|         10|      raushan| jaipur|     05-02-2023|       null|      null|    null|            null|\n|       null|         null|   null|           null|         11|        12|      76|      12-03-2023|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_df.join(sales_df, sales_df[\"customer_id\"]==customer_df[\"customer_id\"], \"full\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d54cd693-abe5-443e-ad81-cf8beeecc95f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+\n|customer_id|customer_name|address|date_of_joining|\n+-----------+-------------+-------+---------------+\n|          1|       manish|  patna|     30-05-2022|\n|          2|       vikash|kolkata|     12-03-2023|\n|          5|       mahesh| jaipur|     22-03-2023|\n|          7|        raman|  patna|     30-12-2022|\n|          9|       ragini|kolkata|     03-03-2023|\n+-----------+-------------+-------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_df.join(sales_df, sales_df[\"customer_id\"]==customer_df[\"customer_id\"], \"left_semi\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3901503-569d-45fd-a464-3f0ce30f8a34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+\n|customer_id|customer_name|address|date_of_joining|\n+-----------+-------------+-------+---------------+\n|          3|       nikita|  delhi|     25-06-2023|\n|          4|        rahul| ranchi|     24-03-2023|\n|          6|     prantosh|kolkata|     18-10-2022|\n|          8|      prakash| ranchi|     24-02-2023|\n|         10|      raushan| jaipur|     05-02-2023|\n+-----------+-------------+-------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "customer_df.join(sales_df, sales_df[\"customer_id\"]==customer_df[\"customer_id\"], \"left_anti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e42e0816-ff2b-4103-aad0-6b779e8762bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|customer_id|customer_name|address|date_of_joining|customer_id|product_id|quantity|date_of_purchase|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|          1|       manish|  patna|     30-05-2022|          1|        22|      10|      01-06-2022|\n|          1|       manish|  patna|     30-05-2022|          1|        27|       5|      03-02-2023|\n|          1|       manish|  patna|     30-05-2022|          2|         5|       3|      01-06-2023|\n|          1|       manish|  patna|     30-05-2022|          5|        22|       1|      22-03-2023|\n|          1|       manish|  patna|     30-05-2022|          7|        22|       4|      03-02-2023|\n|          1|       manish|  patna|     30-05-2022|          9|         5|       6|      03-03-2023|\n|          1|       manish|  patna|     30-05-2022|          2|         1|      12|      15-06-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        56|       2|      25-06-2023|\n|          1|       manish|  patna|     30-05-2022|          5|        12|       5|      15-04-2023|\n|          1|       manish|  patna|     30-05-2022|         11|        12|      76|      12-03-2023|\n|          2|       vikash|kolkata|     12-03-2023|          1|        22|      10|      01-06-2022|\n|          2|       vikash|kolkata|     12-03-2023|          1|        27|       5|      03-02-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         5|       3|      01-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          5|        22|       1|      22-03-2023|\n|          2|       vikash|kolkata|     12-03-2023|          7|        22|       4|      03-02-2023|\n|          2|       vikash|kolkata|     12-03-2023|          9|         5|       6|      03-03-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         1|      12|      15-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          1|        56|       2|      25-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          5|        12|       5|      15-04-2023|\n|          2|       vikash|kolkata|     12-03-2023|         11|        12|      76|      12-03-2023|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customer_df.crossJoin(sales_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5efb77a0-fdb5-42c0-b6f9-bbd0bb97acb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Leet code Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9fef4a0-8441-4fbe-9fdd-7ad2e7a9553f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+\n|person_id|last_name|first_name|\n+---------+---------+----------+\n|        1|     Wang|     Allen|\n|        2|    Alice|       Bob|\n+---------+---------+----------+\n\n"
     ]
    }
   ],
   "source": [
    " person_data = [(1,'Wang','Allen'),\n",
    " (2,'Alice','Bob')]    \n",
    "\n",
    " person_schema = ['person_id', 'last_name', 'first_name']\n",
    "\n",
    " person_df = spark.createDataFrame(data=person_data, schema=person_schema)\n",
    "\n",
    " person_df.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbda886a-a7c4-479b-95a0-b21c86b40778",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+----------+\n|address_id|person_id|         city|     state|\n+----------+---------+-------------+----------+\n|         1|        2|New York City|  New York|\n|         2|        3|     Leetcode|California|\n+----------+---------+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "address_data = [\n",
    "    (1, 2, 'New York City', 'New York'),\n",
    "    (2, 3, 'Leetcode', 'California')\n",
    "    ]\n",
    "\n",
    "address_schema = ['address_id', 'person_id', 'city', 'state']\n",
    "\n",
    "address_df = spark.createDataFrame(data=address_data, schema=address_schema)\n",
    "\n",
    "address_df.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdf618e0-e968-46ef-ae60-92cc30d94b5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+--------+\n|first_name|last_name|         city|   state|\n+----------+---------+-------------+--------+\n|     Allen|     Wang|         null|    null|\n|       Bob|    Alice|New York City|New York|\n+----------+---------+-------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "person_df.join(address_df, person_df['person_id']==address_df['person_id'], \"left\")\\\n",
    "    .select(person_df['first_name'], person_df['last_name'], address_df['city'], address_df['state']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "836a030a-67e3-43e0-80e7-8f377f069c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba45e170-d80b-417f-90de-0c9677af762b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+\n| id|    name|salary|     dept|gender|\n+---+--------+------+---------+------+\n|  1|  manish| 50000|       IT|     m|\n|  2|  vikash| 60000|    sales|     m|\n|  3| raushan| 70000|marketing|     m|\n|  4|  mukesh| 80000|       IT|     m|\n|  5|   priti| 90000|    sales|     f|\n|  6|  nikita| 45000|marketing|     f|\n|  7|  ragini| 55000|marketing|     f|\n|  8|   rashi|100000|       IT|     f|\n|  9|  aditya| 65000|       IT|     m|\n| 10|   rahul| 50000|marketing|     m|\n| 11|   rakhi| 50000|       IT|     f|\n| 12|akhilesh| 90000|    sales|     m|\n+---+--------+------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_d = [(1,'manish',50000,'IT','m'),\n",
    "(2,'vikash',60000,'sales','m'),\n",
    "(3,'raushan',70000,'marketing','m'),\n",
    "(4,'mukesh',80000,'IT','m'),\n",
    "(5,'priti',90000,'sales','f'),\n",
    "(6,'nikita',45000,'marketing','f'),\n",
    "(7,'ragini',55000,'marketing','f'),\n",
    "(8,'rashi',100000,'IT','f'),\n",
    "(9,'aditya',65000,'IT','m'),\n",
    "(10,'rahul',50000,'marketing','m'),\n",
    "(11,'rakhi',50000,'IT','f'),\n",
    "(12,'akhilesh',90000,'sales','m')]\n",
    "\n",
    "emp_s = ['id', 'name', 'salary', 'dept', 'gender']\n",
    "\n",
    "emp_dff = spark.createDataFrame(data=emp_d, schema=emp_s)\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b704948c-0221-4722-b8bb-013ed942f0b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n|     dept|sum(salary)|\n+---------+-----------+\n|       IT|     345000|\n|marketing|     220000|\n|    sales|     240000|\n+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_dff.groupBy(\"dept\").sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4722ba8f-f291-477c-b02b-c5dc21c09fff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+------------+\n| id|    name|salary|     dept|gender|total_salary|\n+---+--------+------+---------+------+------------+\n|  1|  manish| 50000|       IT|     m|      345000|\n|  4|  mukesh| 80000|       IT|     m|      345000|\n|  8|   rashi|100000|       IT|     f|      345000|\n|  9|  aditya| 65000|       IT|     m|      345000|\n| 11|   rakhi| 50000|       IT|     f|      345000|\n|  3| raushan| 70000|marketing|     m|      220000|\n|  6|  nikita| 45000|marketing|     f|      220000|\n|  7|  ragini| 55000|marketing|     f|      220000|\n| 10|   rahul| 50000|marketing|     m|      220000|\n|  2|  vikash| 60000|    sales|     m|      240000|\n|  5|   priti| 90000|    sales|     f|      240000|\n| 12|akhilesh| 90000|    sales|     m|      240000|\n+---+--------+------+---------+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.partitionBy(\"dept\")\n",
    "emp_dff = emp_dff.withColumn(\"total_salary\", sum(\"salary\").over(window=window))\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30bf4aff-bc59-45a9-83ec-76793a91103f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+------------+-----+----------+\n| id|    name|salary|     dept|gender|total_salary|Order|Row_number|\n+---+--------+------+---------+------+------------+-----+----------+\n|  1|  manish| 50000|       IT|     m|      345000|    1|         1|\n| 11|   rakhi| 50000|       IT|     f|      345000|    1|         2|\n|  9|  aditya| 65000|       IT|     m|      345000|    2|         3|\n|  4|  mukesh| 80000|       IT|     m|      345000|    3|         4|\n|  8|   rashi|100000|       IT|     f|      345000|    4|         5|\n|  6|  nikita| 45000|marketing|     f|      220000|    1|         1|\n| 10|   rahul| 50000|marketing|     m|      220000|    2|         2|\n|  7|  ragini| 55000|marketing|     f|      220000|    3|         3|\n|  3| raushan| 70000|marketing|     m|      220000|    4|         4|\n|  2|  vikash| 60000|    sales|     m|      240000|    1|         1|\n|  5|   priti| 90000|    sales|     f|      240000|    2|         2|\n| 12|akhilesh| 90000|    sales|     m|      240000|    2|         3|\n+---+--------+------+---------+------+------------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.partitionBy(\"dept\").orderBy(\"salary\")\n",
    "emp_dff = emp_dff.withColumn(\"Row_number\", row_number().over(window=window))\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdd421a6-9f62-43f8-879a-51d867736559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+------------+-----+----------+----+\n| id|    name|salary|     dept|gender|total_salary|Order|Row_number|Rank|\n+---+--------+------+---------+------+------------+-----+----------+----+\n|  1|  manish| 50000|       IT|     m|      345000|    1|         1|   1|\n| 11|   rakhi| 50000|       IT|     f|      345000|    1|         2|   1|\n|  9|  aditya| 65000|       IT|     m|      345000|    2|         3|   3|\n|  4|  mukesh| 80000|       IT|     m|      345000|    3|         4|   4|\n|  8|   rashi|100000|       IT|     f|      345000|    4|         5|   5|\n|  6|  nikita| 45000|marketing|     f|      220000|    1|         1|   1|\n| 10|   rahul| 50000|marketing|     m|      220000|    2|         2|   2|\n|  7|  ragini| 55000|marketing|     f|      220000|    3|         3|   3|\n|  3| raushan| 70000|marketing|     m|      220000|    4|         4|   4|\n|  2|  vikash| 60000|    sales|     m|      240000|    1|         1|   1|\n|  5|   priti| 90000|    sales|     f|      240000|    2|         2|   2|\n| 12|akhilesh| 90000|    sales|     m|      240000|    2|         3|   2|\n+---+--------+------+---------+------+------------+-----+----------+----+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"dept\").orderBy(\"salary\")\n",
    "emp_dff = emp_dff.withColumn(\"Rank\", rank().over(window=window))\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e90c16-f683-43bf-8fd2-0bc856289f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+------------+-----+----------+----+----------+\n| id|    name|salary|     dept|gender|total_salary|Order|Row_number|Rank|Dense_Rank|\n+---+--------+------+---------+------+------------+-----+----------+----+----------+\n|  1|  manish| 50000|       IT|     m|      345000|    1|         1|   1|         1|\n| 11|   rakhi| 50000|       IT|     f|      345000|    1|         2|   1|         1|\n|  9|  aditya| 65000|       IT|     m|      345000|    2|         3|   3|         2|\n|  4|  mukesh| 80000|       IT|     m|      345000|    3|         4|   4|         3|\n|  8|   rashi|100000|       IT|     f|      345000|    4|         5|   5|         4|\n|  6|  nikita| 45000|marketing|     f|      220000|    1|         1|   1|         1|\n| 10|   rahul| 50000|marketing|     m|      220000|    2|         2|   2|         2|\n|  7|  ragini| 55000|marketing|     f|      220000|    3|         3|   3|         3|\n|  3| raushan| 70000|marketing|     m|      220000|    4|         4|   4|         4|\n|  2|  vikash| 60000|    sales|     m|      240000|    1|         1|   1|         1|\n|  5|   priti| 90000|    sales|     f|      240000|    2|         2|   2|         2|\n| 12|akhilesh| 90000|    sales|     m|      240000|    2|         3|   2|         2|\n+---+--------+------+---------+------+------------+-----+----------+----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"dept\").orderBy(\"salary\")\n",
    "emp_dff = emp_dff.withColumn(\"Dense_Rank\", dense_rank().over(window=window))\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48f304d6-267b-43f5-916d-83672fbd2e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+------------+-----+----------+----+----------+\n| id|    name|salary|     dept|gender|total_salary|Order|row_number|rank|dense_rank|\n+---+--------+------+---------+------+------------+-----+----------+----+----------+\n|  1|  manish| 50000|       IT|     m|      345000|    1|         1|   1|         1|\n| 11|   rakhi| 50000|       IT|     f|      345000|    1|         2|   1|         1|\n|  9|  aditya| 65000|       IT|     m|      345000|    2|         3|   3|         2|\n|  4|  mukesh| 80000|       IT|     m|      345000|    3|         4|   4|         3|\n|  8|   rashi|100000|       IT|     f|      345000|    4|         5|   5|         4|\n|  6|  nikita| 45000|marketing|     f|      220000|    1|         1|   1|         1|\n| 10|   rahul| 50000|marketing|     m|      220000|    2|         2|   2|         2|\n|  7|  ragini| 55000|marketing|     f|      220000|    3|         3|   3|         3|\n|  3| raushan| 70000|marketing|     m|      220000|    4|         4|   4|         4|\n|  2|  vikash| 60000|    sales|     m|      240000|    1|         1|   1|         1|\n|  5|   priti| 90000|    sales|     f|      240000|    2|         2|   2|         2|\n| 12|akhilesh| 90000|    sales|     m|      240000|    2|         3|   2|         2|\n+---+--------+------+---------+------+------------+-----+----------+----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"dept\").orderBy(\"salary\")\n",
    "emp_dff = emp_dff.withColumn(\"row_number\", row_number().over(window=window))\\\n",
    "    .withColumn(\"rank\", rank().over(window=window))\\\n",
    "        .withColumn(\"dense_rank\", dense_rank().over(window=window)\n",
    "                             )\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ccf2d6d-b097-4850-98c4-cc82e3dcc0d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------------+-----+----------+----+----------+\n| id|  name|salary|dept|gender|total_salary|Order|row_number|rank|dense_rank|\n+---+------+------+----+------+------------+-----+----------+----+----------+\n|  8| rashi|100000|  IT|     f|      345000|    4|         1|   1|         1|\n|  4|mukesh| 80000|  IT|     m|      345000|    3|         1|   1|         1|\n+---+------+------+----+------+------------+-----+----------+----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"dept\", \"gender\").orderBy(\"salary\")\n",
    "emp_dff = emp_dff.withColumn(\"row_number\", row_number().over(window=window))\\\n",
    "    .withColumn(\"rank\", rank().over(window=window))\\\n",
    "        .withColumn(\"dense_rank\", dense_rank().over(window=window)\n",
    "                             )\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd5728c-cb64-44cb-ad22-9c8aef45b581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------------+-----+----------+----+----------+\n| id|  name|salary|dept|gender|total_salary|Order|row_number|rank|dense_rank|\n+---+------+------+----+------+------------+-----+----------+----+----------+\n|  8| rashi|100000|  IT|     f|      345000|    4|         1|   1|         1|\n|  4|mukesh| 80000|  IT|     m|      345000|    3|         2|   2|         2|\n+---+------+------+----+------+------------+-----+----------+----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"dept\").orderBy(desc(\"salary\"))\n",
    "emp_dff = emp_dff.withColumn(\"row_number\", row_number().over(window=window))\\\n",
    "    .withColumn(\"rank\", rank().over(window=window))\\\n",
    "        .withColumn(\"dense_rank\", dense_rank().over(window=window)\\\n",
    "                             ).filter(col(\"dense_rank\")<=2)\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6e5cbbf-4fa5-4ae3-ae27-7bd02fef8b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------------+-----+----------+----+----------+\n| id|  name|salary|dept|gender|total_salary|Order|row_number|rank|dense_rank|\n+---+------+------+----+------+------------+-----+----------+----+----------+\n|  8| rashi|100000|  IT|     f|      345000|    4|         1|   1|         1|\n|  4|mukesh| 80000|  IT|     m|      345000|    3|         2|   2|         2|\n+---+------+------+----+------+------------+-----+----------+----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"dept\").orderBy(desc(\"salary\"))\n",
    "emp_dff = emp_dff.withColumn(\"row_number\", row_number().over(window=window))\\\n",
    "    .withColumn(\"rank\", rank().over(window=window))\\\n",
    "        .withColumn(\"dense_rank\", dense_rank().over(window=window)\\\n",
    "                             ).filter(col(\"dense_rank\")<=2).limit(2)\n",
    "\n",
    "emp_dff.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d52886f7-fa91-413d-8a2c-a8a06ad278f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lead and Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f0153b-0c47-4528-8f15-4a0acc7faaef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+\n|product_id|product_name|sales_date|  sales|\n+----------+------------+----------+-------+\n|         1|      iphone|01-01-2023|1500000|\n|         2|     samsung|01-01-2023|1100000|\n|         3|     oneplus|01-01-2023|1100000|\n|         1|      iphone|01-02-2023|1300000|\n|         2|     samsung|01-02-2023|1120000|\n|         3|     oneplus|01-02-2023|1120000|\n|         1|      iphone|01-03-2023|1600000|\n|         2|     samsung|01-03-2023|1080000|\n|         3|     oneplus|01-03-2023|1160000|\n|         1|      iphone|01-04-2023|1700000|\n|         2|     samsung|01-04-2023|1800000|\n|         3|     oneplus|01-04-2023|1170000|\n|         1|      iphone|01-05-2023|1200000|\n|         2|     samsung|01-05-2023| 980000|\n|         3|     oneplus|01-05-2023|1175000|\n|         1|      iphone|01-06-2023|1100000|\n|         2|     samsung|01-06-2023|1100000|\n|         3|     oneplus|01-06-2023|1200000|\n+----------+------------+----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "product_data = [\n",
    "(1,\"iphone\",\"01-01-2023\",1500000),\n",
    "(2,\"samsung\",\"01-01-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-01-2023\",1100000),\n",
    "(1,\"iphone\",\"01-02-2023\",1300000),\n",
    "(2,\"samsung\",\"01-02-2023\",1120000),\n",
    "(3,\"oneplus\",\"01-02-2023\",1120000),\n",
    "(1,\"iphone\",\"01-03-2023\",1600000),\n",
    "(2,\"samsung\",\"01-03-2023\",1080000),\n",
    "(3,\"oneplus\",\"01-03-2023\",1160000),\n",
    "(1,\"iphone\",\"01-04-2023\",1700000),\n",
    "(2,\"samsung\",\"01-04-2023\",1800000),\n",
    "(3,\"oneplus\",\"01-04-2023\",1170000),\n",
    "(1,\"iphone\",\"01-05-2023\",1200000),\n",
    "(2,\"samsung\",\"01-05-2023\",980000),\n",
    "(3,\"oneplus\",\"01-05-2023\",1175000),\n",
    "(1,\"iphone\",\"01-06-2023\",1100000),\n",
    "(2,\"samsung\",\"01-06-2023\",1100000),\n",
    "(3,\"oneplus\",\"01-06-2023\",1200000)\n",
    "]\n",
    "\n",
    "\n",
    "product_schema = ['product_id', 'product_name', 'sales_date', 'sales']\n",
    "\n",
    "product_df = spark.createDataFrame(data=product_data, schema=product_schema)\n",
    "\n",
    "product_df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efaf7389-ff25-4f43-ba35-0c9b338a085d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-------+-------+\n|product_id|product_name|sales_date|  sales|   lead|    lag|\n+----------+------------+----------+-------+-------+-------+\n|         1|      iphone|01-06-2023|1100000|1200000|   null|\n|         1|      iphone|01-05-2023|1200000|1700000|1100000|\n|         1|      iphone|01-04-2023|1700000|1600000|1200000|\n|         1|      iphone|01-03-2023|1600000|1300000|1700000|\n|         1|      iphone|01-02-2023|1300000|1500000|1600000|\n|         1|      iphone|01-01-2023|1500000|   null|1300000|\n|         2|     samsung|01-06-2023|1100000| 980000|   null|\n|         2|     samsung|01-05-2023| 980000|1800000|1100000|\n|         2|     samsung|01-04-2023|1800000|1080000| 980000|\n|         2|     samsung|01-03-2023|1080000|1120000|1800000|\n|         2|     samsung|01-02-2023|1120000|1100000|1080000|\n|         2|     samsung|01-01-2023|1100000|   null|1120000|\n|         3|     oneplus|01-06-2023|1200000|1175000|   null|\n|         3|     oneplus|01-05-2023|1175000|1170000|1200000|\n|         3|     oneplus|01-04-2023|1170000|1160000|1175000|\n|         3|     oneplus|01-03-2023|1160000|1120000|1170000|\n|         3|     oneplus|01-02-2023|1120000|1100000|1160000|\n|         3|     oneplus|01-01-2023|1100000|   null|1120000|\n+----------+------------+----------+-------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"product_id\").orderBy(desc(\"sales_date\"))\n",
    "last_month = product_df.withColumn(\"lead\", lead(col('sales'), 1, \"No value\").over(window=window))\\\n",
    "    .withColumn(\"lag\", lag(col('sales'), ).over(window=window))\n",
    "\n",
    "last_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6600c1d5-be62-400c-8e96-553e24d50cf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-------------------+\n|product_id|product_name|sales_date|  sales|previous_month_loss|\n+----------+------------+----------+-------+-------------------+\n|         1|      iphone|01-01-2023|1500000|               null|\n|         1|      iphone|01-02-2023|1300000|            1500000|\n|         1|      iphone|01-03-2023|1600000|            1300000|\n|         1|      iphone|01-04-2023|1700000|            1600000|\n|         1|      iphone|01-05-2023|1200000|            1700000|\n|         1|      iphone|01-06-2023|1100000|            1200000|\n|         2|     samsung|01-01-2023|1100000|               null|\n|         2|     samsung|01-02-2023|1120000|            1100000|\n|         2|     samsung|01-03-2023|1080000|            1120000|\n|         2|     samsung|01-04-2023|1800000|            1080000|\n|         2|     samsung|01-05-2023| 980000|            1800000|\n|         2|     samsung|01-06-2023|1100000|             980000|\n|         3|     oneplus|01-01-2023|1100000|               null|\n|         3|     oneplus|01-02-2023|1120000|            1100000|\n|         3|     oneplus|01-03-2023|1160000|            1120000|\n|         3|     oneplus|01-04-2023|1170000|            1160000|\n|         3|     oneplus|01-05-2023|1175000|            1170000|\n|         3|     oneplus|01-06-2023|1200000|            1175000|\n+----------+------------+----------+-------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"product_id\").orderBy(\"sales_date\")\n",
    "last_month = product_df.withColumn(\"previous_month_loss\", lag(col('sales'), 1, \"null\").over(window=window))\n",
    "\n",
    "last_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed498e50-ad21-406d-a63b-2bafe4e3d108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-------------------+---------------+\n|product_id|product_name|sales_date|  sales|previous_month_loss|loss_percentage|\n+----------+------------+----------+-------+-------------------+---------------+\n|         1|      iphone|01-01-2023|1500000|               null|           null|\n|         1|      iphone|01-02-2023|1300000|            1500000|          -15.0|\n|         1|      iphone|01-03-2023|1600000|            1300000|           19.0|\n|         1|      iphone|01-04-2023|1700000|            1600000|            6.0|\n|         1|      iphone|01-05-2023|1200000|            1700000|          -42.0|\n|         1|      iphone|01-06-2023|1100000|            1200000|           -9.0|\n|         2|     samsung|01-01-2023|1100000|               null|           null|\n|         2|     samsung|01-02-2023|1120000|            1100000|            2.0|\n|         2|     samsung|01-03-2023|1080000|            1120000|           -4.0|\n|         2|     samsung|01-04-2023|1800000|            1080000|           40.0|\n|         2|     samsung|01-05-2023| 980000|            1800000|          -84.0|\n|         2|     samsung|01-06-2023|1100000|             980000|           11.0|\n|         3|     oneplus|01-01-2023|1100000|               null|           null|\n|         3|     oneplus|01-02-2023|1120000|            1100000|            2.0|\n|         3|     oneplus|01-03-2023|1160000|            1120000|            3.0|\n|         3|     oneplus|01-04-2023|1170000|            1160000|            1.0|\n|         3|     oneplus|01-05-2023|1175000|            1170000|            0.0|\n|         3|     oneplus|01-06-2023|1200000|            1175000|            2.0|\n+----------+------------+----------+-------+-------------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"product_id\").orderBy(\"sales_date\")\n",
    "last_month = last_month.withColumn(\"loss_percentage\",  round(((col('sales') - col('previous_month_loss'))/ col('sales'))*100))\n",
    "\n",
    "last_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03392c8-fb94-4f26-9107-0558ce3e85c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-----------+-------+\n|product_id|product_name|sales_date|  sales|Total Sales|Sales %|\n+----------+------------+----------+-------+-----------+-------+\n|         1|      iphone|01-01-2023|1500000|    8400000|  17.86|\n|         1|      iphone|01-02-2023|1300000|    8400000|  15.48|\n|         1|      iphone|01-03-2023|1600000|    8400000|  19.05|\n|         1|      iphone|01-04-2023|1700000|    8400000|  20.24|\n|         1|      iphone|01-05-2023|1200000|    8400000|  14.29|\n|         1|      iphone|01-06-2023|1100000|    8400000|   13.1|\n|         3|     oneplus|01-01-2023|1100000|    6925000|  15.88|\n|         3|     oneplus|01-02-2023|1120000|    6925000|  16.17|\n|         3|     oneplus|01-03-2023|1160000|    6925000|  16.75|\n|         3|     oneplus|01-04-2023|1170000|    6925000|   16.9|\n|         3|     oneplus|01-05-2023|1175000|    6925000|  16.97|\n|         3|     oneplus|01-06-2023|1200000|    6925000|  17.33|\n|         2|     samsung|01-01-2023|1100000|    7180000|  15.32|\n|         2|     samsung|01-02-2023|1120000|    7180000|   15.6|\n|         2|     samsung|01-03-2023|1080000|    7180000|  15.04|\n|         2|     samsung|01-04-2023|1800000|    7180000|  25.07|\n|         2|     samsung|01-05-2023| 980000|    7180000|  13.65|\n|         2|     samsung|01-06-2023|1100000|    7180000|  15.32|\n+----------+------------+----------+-------+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "phone_window = Window.partitionBy(\"product_name\")\n",
    "\n",
    "monthly_sales_df = product_df.withColumn(\"Total Sales\",sum(col(\"sales\")).over(phone_window))\\\n",
    " .withColumn(\"Sales %\",round((col(\"sales\")/col(\"Total Sales\"))*100,2))\n",
    "\n",
    "monthly_sales_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "808768fb-a5b3-4d7a-b372-9f9e547b2c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.partitionBy(\"product_id\").orderBy(\"sales_date\").rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "311cafbe-bbe3-46cf-be2a-e88f33f4e951",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-----------+----------+\n|product_id|product_name|sales_date|  sales|first_sales|last_sales|\n+----------+------------+----------+-------+-----------+----------+\n|         1|      iphone|01-01-2023|1500000|    1500000|   1100000|\n|         1|      iphone|01-02-2023|1300000|    1500000|   1100000|\n|         1|      iphone|01-03-2023|1600000|    1500000|   1100000|\n|         1|      iphone|01-04-2023|1700000|    1500000|   1100000|\n|         1|      iphone|01-05-2023|1200000|    1500000|   1100000|\n|         1|      iphone|01-06-2023|1100000|    1500000|   1100000|\n|         2|     samsung|01-01-2023|1100000|    1100000|   1100000|\n|         2|     samsung|01-02-2023|1120000|    1100000|   1100000|\n|         2|     samsung|01-03-2023|1080000|    1100000|   1100000|\n|         2|     samsung|01-04-2023|1800000|    1100000|   1100000|\n|         2|     samsung|01-05-2023| 980000|    1100000|   1100000|\n|         2|     samsung|01-06-2023|1100000|    1100000|   1100000|\n|         3|     oneplus|01-01-2023|1100000|    1100000|   1200000|\n|         3|     oneplus|01-02-2023|1120000|    1100000|   1200000|\n|         3|     oneplus|01-03-2023|1160000|    1100000|   1200000|\n|         3|     oneplus|01-04-2023|1170000|    1100000|   1200000|\n|         3|     oneplus|01-05-2023|1175000|    1100000|   1200000|\n|         3|     oneplus|01-06-2023|1200000|    1100000|   1200000|\n+----------+------------+----------+-------+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "product_df.withColumn(\"first_sales\", first(\"sales\").over(window))\\\n",
    "    .withColumn(\"last_sales\", last(\"sales\").over(window)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "995440cc-70db-4ac9-b422-0f5f05b1362c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Window [product_id#8107L, product_name#8108, sales_date#8109, sales#8110L, first(sales#8110L, false) windowspecdefinition(product_id#8107L, sales_date#8109 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS first_sales#8673L, last(sales#8110L, false) windowspecdefinition(product_id#8107L, sales_date#8109 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS last_sales#8680L], [product_id#8107L], [sales_date#8109 ASC NULLS FIRST]\n   +- Sort [product_id#8107L ASC NULLS FIRST, sales_date#8109 ASC NULLS FIRST], false, 0\n      +- Exchange hashpartitioning(product_id#8107L, 200), ENSURE_REQUIREMENTS, [plan_id=11186]\n         +- Scan ExistingRDD[product_id#8107L,product_name#8108,sales_date#8109,sales#8110L]\n\n\n"
     ]
    }
   ],
   "source": [
    "product_df.withColumn(\"first_sales\", first(\"sales\").over(window))\\\n",
    "    .withColumn(\"last_sales\", last(\"sales\").over(window)).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bcdbbc7-842f-4370-8fdc-8d4b99d51611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-----------+----------+\n|product_id|product_name|sales_date|  sales|first_sales|last_sales|\n+----------+------------+----------+-------+-----------+----------+\n|         1|      iphone|01-01-2023|1500000|    1500000|   1100000|\n|         1|      iphone|01-02-2023|1300000|    1500000|   1100000|\n|         1|      iphone|01-03-2023|1600000|    1500000|   1100000|\n|         1|      iphone|01-04-2023|1700000|    1500000|   1100000|\n|         1|      iphone|01-05-2023|1200000|    1500000|   1100000|\n|         1|      iphone|01-06-2023|1100000|    1500000|   1100000|\n|         2|     samsung|01-01-2023|1100000|    1100000|   1100000|\n|         2|     samsung|01-02-2023|1120000|    1100000|   1100000|\n|         2|     samsung|01-03-2023|1080000|    1100000|   1100000|\n|         2|     samsung|01-04-2023|1800000|    1100000|   1100000|\n|         2|     samsung|01-05-2023| 980000|    1100000|   1100000|\n|         2|     samsung|01-06-2023|1100000|    1100000|   1100000|\n|         3|     oneplus|01-01-2023|1100000|    1100000|   1200000|\n|         3|     oneplus|01-02-2023|1120000|    1100000|   1200000|\n|         3|     oneplus|01-03-2023|1160000|    1100000|   1200000|\n|         3|     oneplus|01-04-2023|1170000|    1100000|   1200000|\n|         3|     oneplus|01-05-2023|1175000|    1100000|   1200000|\n|         3|     oneplus|01-06-2023|1200000|    1100000|   1200000|\n+----------+------------+----------+-------+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "new_prod = product_df.withColumn(\"first_sales\", first(\"sales\").over(window))\\\n",
    "    .withColumn(\"last_sales\", last(\"sales\").over(window))\n",
    "\n",
    "new_prod.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05ff9e8c-b086-45e0-a757-6390223fbaa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-------+-----------+----------+\n|product_id|product_name|sales_date|  sales|first_sales|last_sales|\n+----------+------------+----------+-------+-----------+----------+\n|         1|      iphone|01-01-2023|1500000|    1500000|   1100000|\n|         1|      iphone|01-02-2023|1300000|    1500000|   1100000|\n|         1|      iphone|01-03-2023|1600000|    1500000|   1100000|\n|         1|      iphone|01-04-2023|1700000|    1500000|   1100000|\n|         1|      iphone|01-05-2023|1200000|    1500000|   1100000|\n|         1|      iphone|01-06-2023|1100000|    1500000|   1100000|\n|         2|     samsung|01-01-2023|1100000|    1100000|   1100000|\n|         2|     samsung|01-02-2023|1120000|    1100000|   1100000|\n|         2|     samsung|01-03-2023|1080000|    1100000|   1100000|\n|         2|     samsung|01-04-2023|1800000|    1100000|   1100000|\n|         2|     samsung|01-05-2023| 980000|    1100000|   1100000|\n|         2|     samsung|01-06-2023|1100000|    1100000|   1100000|\n|         3|     oneplus|01-01-2023|1100000|    1100000|   1200000|\n|         3|     oneplus|01-02-2023|1120000|    1100000|   1200000|\n|         3|     oneplus|01-03-2023|1160000|    1100000|   1200000|\n|         3|     oneplus|01-04-2023|1170000|    1100000|   1200000|\n|         3|     oneplus|01-05-2023|1175000|    1100000|   1200000|\n|         3|     oneplus|01-06-2023|1200000|    1100000|   1200000|\n+----------+------------+----------+-------+-----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "new_prod = product_df.withColumn(\"first_sales\", first(\"sales\").over(window))\\\n",
    "    .withColumn(\"last_sales\", last(\"sales\").over(window))\n",
    "\n",
    "new_prod.distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fccb9d1-7cdc-405d-b7ba-597b52c97808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Flatten Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401c7e2f-dc87-48e1-a66a-7c7e489da2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------------------+-------------+-------------+-------------+------+\n|code|message|         restaurants|results_found|results_shown|results_start|status|\n+----+-------+--------------------+-------------+-------------+-------------+------+\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|[{{{17066603}, b9...|         6835|           20|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|[{{{17093124}, b9...|         8680|           20|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|[{{{17580142}, b9...|          943|           20|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|[{{{17284158}, b9...|          257|           20|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|[{{{17678233}, b9...|          358|           20|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|[{{{17375047}, b9...|          641|           20|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|                  []|            0|            0|            1|  null|\n|null|   null|[{{{17616590}, b9...|         1613|           20|            1|  null|\n+----+-------+--------------------+-------------+-------------+-------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "res_df = spark.read.format(\"json\")\\\n",
    "    .option(\"multiline\", \"true\")\\\n",
    "        .option(\"inferschema\", \"true\")\\\n",
    "            .load(\"/FileStore/tables/resturant_json_data.json\")\n",
    "\n",
    "res_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b752755e-f377-4c1a-b7db-311d74c69ea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- code: long (nullable = true)\n |-- message: string (nullable = true)\n |-- restaurants: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- restaurant: struct (nullable = true)\n |    |    |    |-- R: struct (nullable = true)\n |    |    |    |    |-- res_id: long (nullable = true)\n |    |    |    |-- apikey: string (nullable = true)\n |    |    |    |-- average_cost_for_two: long (nullable = true)\n |    |    |    |-- cuisines: string (nullable = true)\n |    |    |    |-- currency: string (nullable = true)\n |    |    |    |-- deeplink: string (nullable = true)\n |    |    |    |-- establishment_types: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |-- events_url: string (nullable = true)\n |    |    |    |-- featured_image: string (nullable = true)\n |    |    |    |-- has_online_delivery: long (nullable = true)\n |    |    |    |-- has_table_booking: long (nullable = true)\n |    |    |    |-- id: string (nullable = true)\n |    |    |    |-- is_delivering_now: long (nullable = true)\n |    |    |    |-- location: struct (nullable = true)\n |    |    |    |    |-- address: string (nullable = true)\n |    |    |    |    |-- city: string (nullable = true)\n |    |    |    |    |-- city_id: long (nullable = true)\n |    |    |    |    |-- country_id: long (nullable = true)\n |    |    |    |    |-- latitude: string (nullable = true)\n |    |    |    |    |-- locality: string (nullable = true)\n |    |    |    |    |-- locality_verbose: string (nullable = true)\n |    |    |    |    |-- longitude: string (nullable = true)\n |    |    |    |    |-- zipcode: string (nullable = true)\n |    |    |    |-- menu_url: string (nullable = true)\n |    |    |    |-- name: string (nullable = true)\n |    |    |    |-- offers: array (nullable = true)\n |    |    |    |    |-- element: string (containsNull = true)\n |    |    |    |-- photos_url: string (nullable = true)\n |    |    |    |-- price_range: long (nullable = true)\n |    |    |    |-- switch_to_order_menu: long (nullable = true)\n |    |    |    |-- thumb: string (nullable = true)\n |    |    |    |-- url: string (nullable = true)\n |    |    |    |-- user_rating: struct (nullable = true)\n |    |    |    |    |-- aggregate_rating: string (nullable = true)\n |    |    |    |    |-- rating_color: string (nullable = true)\n |    |    |    |    |-- rating_text: string (nullable = true)\n |    |    |    |    |-- votes: string (nullable = true)\n |-- results_found: long (nullable = true)\n |-- results_shown: long (nullable = true)\n |-- results_start: string (nullable = true)\n |-- status: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "res_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2565d59b-394b-46fb-935a-f05da0c718db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- code: long (nullable = true)\n |-- message: string (nullable = true)\n |-- results_found: long (nullable = true)\n |-- results_shown: long (nullable = true)\n |-- results_start: string (nullable = true)\n |-- status: string (nullable = true)\n |-- new_res: struct (nullable = true)\n |    |-- restaurant: struct (nullable = true)\n |    |    |-- R: struct (nullable = true)\n |    |    |    |-- res_id: long (nullable = true)\n |    |    |-- apikey: string (nullable = true)\n |    |    |-- average_cost_for_two: long (nullable = true)\n |    |    |-- cuisines: string (nullable = true)\n |    |    |-- currency: string (nullable = true)\n |    |    |-- deeplink: string (nullable = true)\n |    |    |-- establishment_types: array (nullable = true)\n |    |    |    |-- element: string (containsNull = true)\n |    |    |-- events_url: string (nullable = true)\n |    |    |-- featured_image: string (nullable = true)\n |    |    |-- has_online_delivery: long (nullable = true)\n |    |    |-- has_table_booking: long (nullable = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- is_delivering_now: long (nullable = true)\n |    |    |-- location: struct (nullable = true)\n |    |    |    |-- address: string (nullable = true)\n |    |    |    |-- city: string (nullable = true)\n |    |    |    |-- city_id: long (nullable = true)\n |    |    |    |-- country_id: long (nullable = true)\n |    |    |    |-- latitude: string (nullable = true)\n |    |    |    |-- locality: string (nullable = true)\n |    |    |    |-- locality_verbose: string (nullable = true)\n |    |    |    |-- longitude: string (nullable = true)\n |    |    |    |-- zipcode: string (nullable = true)\n |    |    |-- menu_url: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |    |    |-- offers: array (nullable = true)\n |    |    |    |-- element: string (containsNull = true)\n |    |    |-- photos_url: string (nullable = true)\n |    |    |-- price_range: long (nullable = true)\n |    |    |-- switch_to_order_menu: long (nullable = true)\n |    |    |-- thumb: string (nullable = true)\n |    |    |-- url: string (nullable = true)\n |    |    |-- user_rating: struct (nullable = true)\n |    |    |    |-- aggregate_rating: string (nullable = true)\n |    |    |    |-- rating_color: string (nullable = true)\n |    |    |    |-- rating_text: string (nullable = true)\n |    |    |    |-- votes: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "res_df.select(\"*\", explode(\"restaurants\").alias(\"new_res\")).drop(\"restaurants\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23fe92ef-d274-4913-8213-31bbcde1c4cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|  res_id|\n+--------+\n|17066603|\n|17059541|\n|17064405|\n|17057797|\n|17057591|\n|17064266|\n|17060516|\n|17060320|\n|17059060|\n|17059012|\n|17060869|\n|17061231|\n|17058534|\n|17057925|\n|17064031|\n|17061237|\n|17061253|\n|17061296|\n|17061205|\n|17057397|\n+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "res_df.select(\"*\", explode(\"restaurants\").alias(\"new_res\")).drop(\"restaurants\")\\\n",
    "    .select(\"*\",\"new_res.restaurant.R.res_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30df49ca-6209-46b2-b3ec-649f2859f5c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- code: long (nullable = true)\n |-- message: string (nullable = true)\n |-- results_found: long (nullable = true)\n |-- results_shown: long (nullable = true)\n |-- results_start: string (nullable = true)\n |-- status: string (nullable = true)\n |-- new_res: struct (nullable = true)\n |    |-- restaurant: struct (nullable = true)\n |    |    |-- R: struct (nullable = true)\n |    |    |    |-- res_id: long (nullable = true)\n |    |    |-- apikey: string (nullable = true)\n |    |    |-- average_cost_for_two: long (nullable = true)\n |    |    |-- cuisines: string (nullable = true)\n |    |    |-- currency: string (nullable = true)\n |    |    |-- deeplink: string (nullable = true)\n |    |    |-- establishment_types: array (nullable = true)\n |    |    |    |-- element: string (containsNull = true)\n |    |    |-- events_url: string (nullable = true)\n |    |    |-- featured_image: string (nullable = true)\n |    |    |-- has_online_delivery: long (nullable = true)\n |    |    |-- has_table_booking: long (nullable = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- is_delivering_now: long (nullable = true)\n |    |    |-- location: struct (nullable = true)\n |    |    |    |-- address: string (nullable = true)\n |    |    |    |-- city: string (nullable = true)\n |    |    |    |-- city_id: long (nullable = true)\n |    |    |    |-- country_id: long (nullable = true)\n |    |    |    |-- latitude: string (nullable = true)\n |    |    |    |-- locality: string (nullable = true)\n |    |    |    |-- locality_verbose: string (nullable = true)\n |    |    |    |-- longitude: string (nullable = true)\n |    |    |    |-- zipcode: string (nullable = true)\n |    |    |-- menu_url: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |    |    |-- offers: array (nullable = true)\n |    |    |    |-- element: string (containsNull = true)\n |    |    |-- photos_url: string (nullable = true)\n |    |    |-- price_range: long (nullable = true)\n |    |    |-- switch_to_order_menu: long (nullable = true)\n |    |    |-- thumb: string (nullable = true)\n |    |    |-- url: string (nullable = true)\n |    |    |-- user_rating: struct (nullable = true)\n |    |    |    |-- aggregate_rating: string (nullable = true)\n |    |    |    |-- rating_color: string (nullable = true)\n |    |    |    |-- rating_text: string (nullable = true)\n |    |    |    |-- votes: string (nullable = true)\n |-- res_id: long (nullable = true)\n |-- new_est: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "res_df.select(\"*\", explode(\"restaurants\").alias(\"new_res\")).drop(\"restaurants\")\\\n",
    "    .select(\"*\",\"new_res.restaurant.R.res_id\", explode(\"new_res.restaurant.establishment_types\").alias(\"new_est\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19ed7343-4c65-42f3-8f16-b26cc29ecae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+-------------+-------------+------+--------+-------+--------------------+\n|code|message|results_found|results_shown|results_start|status|  res_id|new_est|                name|\n+----+-------+-------------+-------------+-------------+------+--------+-------+--------------------+\n|null|   null|         6835|           20|            1|  null|17066603|   null|            The Coop|\n|null|   null|         6835|           20|            1|  null|17059541|   null|Maggiano's Little...|\n|null|   null|         6835|           20|            1|  null|17064405|   null|Tako Cheena by Po...|\n|null|   null|         6835|           20|            1|  null|17057797|   null|Bosphorous Turkis...|\n|null|   null|         6835|           20|            1|  null|17057591|   null|Bahama Breeze Isl...|\n|null|   null|         6835|           20|            1|  null|17064266|   null|Hawkers Asian Str...|\n|null|   null|         6835|           20|            1|  null|17060516|   null|Seasons 52 Fresh ...|\n|null|   null|         6835|           20|            1|  null|17060320|   null|Raglan Road Irish...|\n|null|   null|         6835|           20|            1|  null|17059060|   null|           Hillstone|\n|null|   null|         6835|           20|            1|  null|17059012|   null|Hollerbach's Will...|\n|null|   null|         6835|           20|            1|  null|17060869|   null|     Texas de Brazil|\n|null|   null|         6835|           20|            1|  null|17061231|   null|    The Ravenous Pig|\n|null|   null|         6835|           20|            1|  null|17058534|   null|    Earl of Sandwich|\n|null|   null|         6835|           20|            1|  null|17057925|   null|    Caf Tu Tu Tango|\n|null|   null|         6835|           20|            1|  null|17064031|   null|Tibby's New Orlea...|\n|null|   null|         6835|           20|            1|  null|17061237|   null|Cevche Tapas Bar...|\n|null|   null|         6835|           20|            1|  null|17061253|   null| Ethos Vegan Kitchen|\n|null|   null|         6835|           20|            1|  null|17061296|   null|Pom Pom's Teahous...|\n|null|   null|         6835|           20|            1|  null|17061205|   null|     Yellow Dog Eats|\n|null|   null|         6835|           20|            1|  null|17057397|   null|              'Ohana|\n+----+-------+-------------+-------------+-------------+------+--------+-------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "res_df.select(\"*\", explode(\"restaurants\").alias(\"new_res\")).drop(\"restaurants\")\\\n",
    "    .select(\"*\",\"new_res.restaurant.R.res_id\", explode_outer(\"new_res.restaurant.establishment_types\").alias(\"new_est\"),\n",
    "            \"new_res.restaurant.name\").drop(\"new_res\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7e5bfa9-7e4a-4f2c-a54b-f014625bdaa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day10 Spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}