services:
  mysql_source:
    image: mysql:8.0
    container_name: mysql_source
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: newpassword123
      MYSQL_DATABASE: ecommerce_db
      MYSQL_USER: ecomuser
      MYSQL_PASSWORD: ecompassword
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql_init:/docker-entrypoint-initdb.d 
    ports:
      - "3308:3306"

  postgres_dw:
    image: postgres:15
    container_name: postgres_dw
    restart: unless-stopped
    environment:
      POSTGRES_USER: dw_user
      POSTGRES_PASSWORD: dw_password
      POSTGRES_DB: ecommerce_warehouse
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres_init:/docker-entrypoint-initdb.d 
    ports:
      - "5433:5432"

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080' 
      - '7077:7077'
    volumes:
      - ./pyspark_apps:/opt/bitnami/spark/apps
      - ./data_lake:/opt/data_lake 

  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./pyspark_apps:/opt/pyspark_apps
      - ./data_lake:/opt/data_lake 

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile
    image: airflow-custom:2.8.0
    container_name: airflow-init
    depends_on:
      - postgres_dw
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://dw_user:dw_password@postgres_dw:5432/ecommerce_warehouse
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
    volumes:
      - ./airflow_dags:/opt/airflow/dags
      - ./airflow_logs:/opt/airflow/logs
      - ./airflow_plugins:/opt/airflow/plugins
      - ./pyspark_apps/jars:/opt/jars
      - ./data_lake:/opt/data_lake
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --password admin --firstname Air --lastname Flow --role Admin --email admin@example.com
      "

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.8.0
    restart: unless-stopped
    depends_on:
      - airflow-init
      - postgres_dw
      - spark-master
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://dw_user:dw_password@postgres_dw:5432/ecommerce_warehouse
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./airflow_dags:/opt/airflow/dags
      - ./airflow_logs:/opt/airflow/logs
      - ./airflow_plugins:/opt/airflow/plugins
      - ./pyspark_apps:/opt/pyspark_apps
      - ./data_lake:/opt/data_lake
      - ./pyspark_apps/jars:/opt/jars
    ports:
      - "8081:8080"
    command: webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.8.0
    restart: unless-stopped
    depends_on:
      - airflow-init
      - postgres_dw
      - spark-master
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://dw_user:dw_password@postgres_dw:5432/ecommerce_warehouse
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./airflow_dags:/opt/airflow/dags
      - ./airflow_logs:/opt/airflow/logs
      - ./airflow_plugins:/opt/airflow/plugins
      - ./pyspark_apps:/opt/pyspark_apps
      - ./data_lake:/opt/data_lake
      - ./pyspark_apps/jars:/opt/jars
    command: scheduler

  posthog-db:
    image: postgres:15
    container_name: posthog-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: posthog
      POSTGRES_USER: posthog
      POSTGRES_PASSWORD: password
    ports:
    - "5555:5432"   
    volumes:
      - ./posthog_pg_data:/var/lib/postgresql/data


  redis:
    image: redis:7
    container_name: redis
    restart: unless-stopped

  posthog:
    image: posthog/posthog:latest
    container_name: posthog
    restart: unless-stopped
    ports:
      - "8010:8000"
    depends_on:
      - posthog-db
      - redis
    environment:
      - DATABASE_URL=postgres://posthog:password@posthog-db:5432/posthog
      - REDIS_URL=redis://redis:6379
      - SECRET_KEY=6Fmwa_vxaUlBAZriPpwlWqZGmliFX0ws-VFQX3ESL7C1WOBv3zdO-fnbhurT_DWnGnGS5m4IvMi4cd1uQ7o6Kg

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.2.1
    container_name: kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1


  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8090:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    depends_on:
      - kafka
      - zookeeper



  # superset:
  #   image: apache/superset:latest
  #   container_name: superset
  #   restart: unless-stopped
  #   depends_on:
  #     - postgres_dw
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     # SUPERSET_ENV: production
  #     SUPERSET_SECRET_KEY: 6UC2YBe8yLHi173jyPbsAbQ7fjDPjD_VFqwsJXZB0JI
  #     DATABASE_URL: postgresql+psycopg2://dw_user:dw_password@postgres_dw:5432/ecommerce_warehouse
  #   volumes:
  #     - ./superset_home:/app/superset_home
  #   command: >
  #     bash -c "
  #       superset db upgrade &&
  #       superset fab create-admin --username admin --firstname Admin --lastname User --email admin@superset.com --password admin &&
  #       superset init &&
  #       superset run -p 8088 --with-threads --reload --debugger
  #     "

  posthog-consumer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: posthog-consumer
    depends_on:
      - kafka
    restart: always
    command: python event_consumers/posthog_event_consumer.py

  posthog-producer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: posthog-producer
    depends_on:
      - kafka
    restart: on-failure
    command: >
      sh -c "python event_producers/send_event_producer.py $(date +%F)"


  # superset:
  #   image: apache/superset
  #   container_name: superset
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     # - SUPERSET_ENV=production
  #     - SUPERSET_SECRET_KEY=6UC2YBe8yLHi173jyPbsAbQ7fjDPjD_VFqwsJXZB0JI  
  #     # - ADMIN_USERNAME=admin
  #     # - ADMIN_EMAIL=admin@superset.com
  #     # - ADMIN_PASSWORD=admin
  #   depends_on:
  #     - postgres_dw
  #   restart: always
  #   # command:
  #   #   - /bin/sh
  #   #   - -c
  #   #   - >
  #   #     superset db upgrade &&
  #   #     superset init &&
  #   #     superset fab create-admin \
  #   #       --username admin \
  #   #       --firstname Superset \
  #   #       --lastname Admin \
  #   #       --email admin@superset.com \
  #   #       --password admin &&
  #   #     superset run -p 8088 --with-threads --reload --debugger
  #   command: >
  #     /bin/bash -c "
  #     pip install psycopg2-binary &&
  #     superset db upgrade &&
  #     superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password admin &&
  #     superset init &&
  #     superset run -h 0.0.0.0 -p 8088"
  #   volumes:
  #     - superset_home:/opt/superset_home
  #   networks:
  #     - ecommerce_network
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  #     start_period: 60s

  superset:
    image: apache/superset:latest
    container_name: superset
    depends_on:
      - postgres_dw
    ports:
      - "8088:8088"
    environment:
      SUPERSET_SECRET_KEY: "6UC2YBe8yLHi173jyPbsAbQ7fjDPjD_VFqwsJXZB0JI"
    command: >
      /bin/bash -c "
      pip install psycopg2-binary &&
      superset db upgrade &&
      superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password admin &&
      superset init &&
      superset run -h 0.0.0.0 -p 8088"
    volumes:
      - superset_home:/app/superset_home
  
volumes:
  mysql_data:
  postgres_data:
  posthog_pg_data:
  superset_home:

networks:
  default:
    name: ecommerce_network
