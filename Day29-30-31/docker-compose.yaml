# version: '3.8'

# services:
#   mysql:
#     image: mysql:8
#     container_name: mysql
#     environment:
#       MYSQL_ROOT_PASSWORD: root
#       MYSQL_DATABASE: source_db
#     ports:
#       - "3308:3306"
#     volumes:
#       - mysql_data:/var/lib/mysql

#   airflow-init:
#     build:
#       context: .
#     image: custom-airflow-pyspark:latest
#     depends_on:
#       - mysql
#     environment:
#       - _AIRFLOW_WWW_USER_USERNAME=admin
#       - _AIRFLOW_WWW_USER_PASSWORD=admin
#       - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=mysql+pymysql://root:root@mysql:3306/source_db
#     entrypoint: /bin/bash
#     command:
#       - -c
#       - |
#         pip install pymysql &&
#         airflow db init &&
#         airflow users create --username admin --password admin --firstname Air --lastname Flow --role Admin --email admin@example.com
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./data:/opt/airflow/data

#   airflow-webserver:
#     build:
#       context: .
#     image: custom-airflow-pyspark:latest
#     depends_on:
#       - airflow-init
#     ports:
#       - "8080:8080"
#     environment:
#       AIRFLOW__CORE__EXECUTOR: LocalExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://root:root@mysql:3306/source_db
#     command: webserver
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./data:/opt/airflow/data

#   airflow-scheduler:
#     build:
#       context: .
#     image: custom-airflow-pyspark:latest
#     depends_on:
#       - airflow-init
#     environment:
#       AIRFLOW__CORE__EXECUTOR: LocalExecutor
#       AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://root:root@mysql:3306/source_db
#     command: scheduler
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./data:/opt/airflow/data

# volumes:
#   mysql_data:




version: '3.3'

services:
  mysql:
    image: mysql:8
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: newpassword123
      MYSQL_DATABASE: Ecommerce
    ports:
      - "3308:3306"
    volumes:
      - mysql_data:/var/lib/mysql

  airflow-init:
    build:
      context: .
    image: custom-airflow-pyspark:latest
    container_name: airflow-init
    depends_on:
      - mysql
    environment:
      AIRFLOW__LOGGING__REMOTE_LOGGING: "False"
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
      AIRFLOW__WEBSERVER__SECRET_KEY: mySuperSecretKey123
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://root:newpassword123@mysql:3306/Ecommerce
      TZ: Asia/Kolkata
      AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Kolkata
    entrypoint: >
      /bin/bash -c "
        pip install pymysql &&
        airflow db init &&
        airflow users create --username admin --password admin --firstname Air --lastname Flow --role Admin --email admin@example.com
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data

  airflow-webserver:
    build:
      context: .
    image: custom-airflow-pyspark:latest
    container_name: airflow-webserver
    depends_on:
      - airflow-init
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__LOGGING__REMOTE_LOGGING: "False"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://root:newpassword123@mysql:3306/Ecommerce
      AIRFLOW__WEBSERVER__SECRET_KEY: mySuperSecretKey123
      TZ: Asia/Kolkata
      AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Kolkata
    command: webserver
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data

  airflow-scheduler:
    build:
      context: .
    image: custom-airflow-pyspark:latest
    container_name: airflow-scheduler
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__LOGGING__REMOTE_LOGGING: "False"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: mysql+pymysql://root:newpassword123@mysql:3306/Ecommerce
      AIRFLOW__WEBSERVER__SECRET_KEY: mySuperSecretKey123
      TZ: Asia/Kolkata
      AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Kolkata
    command: scheduler
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data

volumes:
  mysql_data:
